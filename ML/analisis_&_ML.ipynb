{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(dirname, filename))\ndf.head()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Limpio los valores NaN y elimino la columna con código de cliente."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('customerID', axis=1, inplace=True)\ndf['TotalCharges'] = df['TotalCharges'].replace(\" \",np.nan)\ndf.dropna(how='any', inplace= True)\ndf['TotalCharges'] = df['TotalCharges'].astype(float)\ndf['SeniorCitizen'] = df['SeniorCitizen'].astype(int)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reviso el porcentaje de clientes dados de baja sobre el total para ver el balance de los Labels.\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=df['Churn'].value_counts().index\nvalues=df['Churn'].value_counts().values\nplt.figure(figsize=(7,7))\nplt.pie(values,labels=labels,autopct='%1.1f%%')\nplt.title('Churn Status',color='black',fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cantidad de meses que los clientes mantuvieron el servicio, según el tipo de plan (Month to Month Contract, One Year Contract, Two Years Contract).\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, sharey = True, figsize = (20,6))\n\nax = sns.distplot(df[df['Contract']=='Month-to-month']['tenure'],\n                   hist=True, kde=False,\n                   bins=int(180/5), color = 'turquoise',\n                   hist_kws={'edgecolor':'black'},\n                   kde_kws={'linewidth': 4},\n                 ax=ax1)\nax.set_ylabel('# de Clientes')\nax.set_xlabel('Tenure (months)')\nax.set_title('Month to Month Contract')\n\nax = sns.distplot(df[df['Contract']=='One year']['tenure'],\n                   hist=True, kde=False,\n                   bins=int(180/5), color = 'steelblue',\n                   hist_kws={'edgecolor':'black'},\n                   kde_kws={'linewidth': 4},\n                 ax=ax2)\nax.set_xlabel('Tenure (months)',size = 14)\nax.set_title('One Year Contract',size = 14)\n\nax = sns.distplot(df[df['Contract']=='Two year']['tenure'],\n                   hist=True, kde=False,\n                   bins=int(180/5), color = 'darkblue',\n                   hist_kws={'edgecolor':'black'},\n                   kde_kws={'linewidth': 4},\n                 ax=ax3)\n\nax.set_xlabel('Tenure (months)')\ntitle = ax.set_title('Two Year Contract')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Transformo todas las columnas que tengan valores Yes/No a valores numéricos 0 o 1.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_convert = ['Partner', 'Dependents','PhoneService','OnlineSecurity' ,\n                      'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies','PaperlessBilling',\n                      'Churn']\n\n\ndf[columns_to_convert] = df[columns_to_convert].replace(dict(Yes=1, No=0))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Transformo las columnas con valores categóricos a valores numéricos.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['gender', 'MultipleLines', 'InternetService', 'Contract', 'PaymentMethod']\n\ndf = pd.get_dummies(data=df, columns= categorical_columns)\n\ndf.isnull().values.any()\ndf.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Divido el dataset en datos de train/test 70/30**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nX = pd.get_dummies(df.drop('Churn', axis=1), drop_first=True)\ny = df['Churn']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estandarizo las columnas numéricas y luego las adhiero de nuevo al dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n\nnumerical_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n\nss = StandardScaler()\nX_train[numerical_columns] = ss.fit_transform(X_train[numerical_columns])\nX_test[numerical_columns] = ss.fit_transform(X_test[numerical_columns])\n#scl = pd.DataFrame(scl, columns=numerical_columns)\n\nX_train.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nnp.where(np.isnan(X_train)) \noversample = SMOTE()\nX_train, y_train = oversample.fit_resample(X_train, y_train)\nX_train.info()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\ncv = StratifiedKFold(n_splits=10, random_state=41, shuffle=True)\ndef evaluar_rendimiento(modelo, nombre, X_train, y_train, cv):\n    s = cross_val_score(modelo, X_train, y_train, cv=cv, n_jobs=-1)\n    print(\"Rendimiento de {}:\\t{:0.3} ± {:0.3}\".format(nombre, s.mean().round(3), s.std().round(3)))\n\ndt = DecisionTreeClassifier()\nevaluar_rendimiento(dt, \"Árbol de decisión\", X_train, y_train, cv)\nab = AdaBoostClassifier()\ngb = GradientBoostingClassifier()\nevaluar_rendimiento(ab,  \"AdaBoostClassifier + GS\", X_train, y_train, cv)\nevaluar_rendimiento(gb, \"GradientBoostingClassifier + GS\", X_train, y_train, cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_ab = {\"n_estimators\": [100, 500],\n             \"learning_rate\":[0.01, 0.1, 1.0],\n             \"base_estimator__max_depth\": [1, 2, 3]}\n\ngrid_ab = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier()), \n                       param_grid=params_ab, cv=cv, verbose=1, n_jobs=-1)\ngrid_ab.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluar_rendimiento(grid_ab.best_estimator_, \"AdaBoostClassifier + GS\", X_train, y_train, cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_gb = {'n_estimators':[100, 500] , \n             'learning_rate':[0.001, 0.001, 0.1, 1.0],\n             'max_depth' : [1, 2, 3, 4]}\n\ngrid_gb = GridSearchCV(gb, param_grid=params_gb, cv=cv, verbose=1, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_gb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluar_rendimiento(grid_gb.best_estimator_, \"GradientBoostingClassifier + GS\", X_train, y_train, cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntreeclf = DecisionTreeClassifier(max_depth=4, random_state=1)\ntreeclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calcular la importancia de los atributos\natributos = X_train.columns\n\npd.DataFrame({'Atributo':atributos,\n              'importancia':treeclf.feature_importances_}).sort_values('importancia',\n                                                                      ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nimport scipy.stats as st\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n\nmodel_xgb = xgb.XGBClassifier(n_jobs=-1)\none_to_left = st.beta(10, 1) # Esta distribución nos dará valores entre 0 y 1 mayormente cercanos a 1\n\nparams = {  \n    \"n_estimators\": st.randint(20,40),  # Número de árboles del ensamble.\n    \"max_depth\": st.randint(3, 12),     # Profundidad máxima de cada árbol.\n    \"learning_rate\": st.uniform(0.05, 0.4), # Learning rate (“eta”)\n    \"colsample_bytree\": one_to_left, # Ratio del subsample de features.\n    \"subsample\": one_to_left,     # Ratio del  subsample de observaciones.\n    \"gamma\": st.uniform(0, 10), # Reducción mínima de la pérdida requerida para seguir splitteando.\n    'reg_alpha': st.uniform(0.05,10),   # Término de regularización L1 de los pesos.\n    \"min_child_weight\": st.uniform(1,20), # Suma mínima de los pesos de una instancia (hessiano) necesaria en un child.\n}\nxgb_cv = RandomizedSearchCV(model_xgb, params, n_iter=25, verbose=True)\nxgb_cv.fit(X_train,y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scikitplot.metrics import plot_roc\nfrom sklearn.metrics import roc_auc_score\n\ny_predicted_xgb = xgb_cv.predict_proba(X_test)\nxgb_auc = roc_auc_score(y_test, y_predicted_xgb[:,1])\nprint(\"El valor del AUC es: \", xgb_auc)\nplot_roc(y_test, y_predicted_xgb, plot_micro=False, plot_macro=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.plot_importance(xgb_cv.best_estimator_, height=0.8, max_num_features=5);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}