{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": " NN_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adrok24/tp_digital_house/blob/main/NN_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "vMj2Yl2Idla3"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "nd1iQobmdla-",
        "outputId": "daeb5b6d-9bc0-46d0-c57b-acc0116809ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = pd.read_csv('Telco.csv')\n",
        "df.head()\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customerID        7043 non-null   object \n",
            " 1   gender            7043 non-null   object \n",
            " 2   SeniorCitizen     7043 non-null   int64  \n",
            " 3   Partner           7043 non-null   object \n",
            " 4   Dependents        7043 non-null   object \n",
            " 5   tenure            7043 non-null   int64  \n",
            " 6   PhoneService      7043 non-null   object \n",
            " 7   MultipleLines     7043 non-null   object \n",
            " 8   InternetService   7043 non-null   object \n",
            " 9   OnlineSecurity    7043 non-null   object \n",
            " 10  OnlineBackup      7043 non-null   object \n",
            " 11  DeviceProtection  7043 non-null   object \n",
            " 12  TechSupport       7043 non-null   object \n",
            " 13  StreamingTV       7043 non-null   object \n",
            " 14  StreamingMovies   7043 non-null   object \n",
            " 15  Contract          7043 non-null   object \n",
            " 16  PaperlessBilling  7043 non-null   object \n",
            " 17  PaymentMethod     7043 non-null   object \n",
            " 18  MonthlyCharges    7043 non-null   float64\n",
            " 19  TotalCharges      7043 non-null   object \n",
            " 20  Churn             7043 non-null   object \n",
            "dtypes: float64(1), int64(2), object(18)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMxRS-c2dlbD"
      },
      "source": [
        "Limpio los valores NaN y elimino la columna con código de cliente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CuSsqttSdlbD"
      },
      "source": [
        "df.drop('customerID', axis=1, inplace=True)\n",
        "df['TotalCharges'] = df['TotalCharges'].replace(\" \",np.nan)\n",
        "df.dropna(how='any', inplace= True)\n",
        "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
        "df['SeniorCitizen'] = df['SeniorCitizen'].astype(int)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MGMqwHvidlbJ"
      },
      "source": [
        "columns_to_convert = ['Partner', 'Dependents','PhoneService','OnlineSecurity' ,\n",
        "                      'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies','PaperlessBilling',\n",
        "                      'Churn']\n",
        "\n",
        "\n",
        "df[columns_to_convert] = df[columns_to_convert].replace(dict(Yes=1, No=0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGx-DOnYdlbO"
      },
      "source": [
        "**Transformo las columnas con valores categóricos a valores numéricos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r3yC7WCYdlbP",
        "outputId": "130ca81d-5e60-42e0-9e9d-6e10d5f5021b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "categorical_columns = ['gender', 'MultipleLines', 'InternetService', 'Contract', 'PaymentMethod']\n",
        "\n",
        "df = pd.get_dummies(data=df, columns= categorical_columns)\n",
        "\n",
        "df.isnull().values.any()\n",
        "df.isnull().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6wRwhfndlbW"
      },
      "source": [
        "**Divido el dataset en datos de train/test 70/30**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uZfa5b6FdlbW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "X = pd.get_dummies(df.drop('Churn', axis=1), drop_first=True)\n",
        "y = df['Churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwJyyAC-dlba"
      },
      "source": [
        "Estandarizo las columnas numéricas y luego las adhiero de nuevo al dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aIXEXuM1dlbc",
        "outputId": "cacd1918-6d80-469e-a294-f205becd9636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "numerical_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_train[numerical_columns] = ss.fit_transform(X_train[numerical_columns])\n",
        "X_test[numerical_columns] = ss.fit_transform(X_test[numerical_columns])\n",
        "#scl = pd.DataFrame(scl, columns=numerical_columns)\n",
        "\n",
        "X_train.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4922 entries, 3404 to 1989\n",
            "Data columns (total 35 columns):\n",
            " #   Column                                   Non-Null Count  Dtype  \n",
            "---  ------                                   --------------  -----  \n",
            " 0   SeniorCitizen                            4922 non-null   int64  \n",
            " 1   Partner                                  4922 non-null   int64  \n",
            " 2   Dependents                               4922 non-null   int64  \n",
            " 3   tenure                                   4922 non-null   float64\n",
            " 4   PhoneService                             4922 non-null   int64  \n",
            " 5   PaperlessBilling                         4922 non-null   int64  \n",
            " 6   MonthlyCharges                           4922 non-null   float64\n",
            " 7   TotalCharges                             4922 non-null   float64\n",
            " 8   gender_Female                            4922 non-null   uint8  \n",
            " 9   gender_Male                              4922 non-null   uint8  \n",
            " 10  MultipleLines_No                         4922 non-null   uint8  \n",
            " 11  MultipleLines_No phone service           4922 non-null   uint8  \n",
            " 12  MultipleLines_Yes                        4922 non-null   uint8  \n",
            " 13  InternetService_DSL                      4922 non-null   uint8  \n",
            " 14  InternetService_Fiber optic              4922 non-null   uint8  \n",
            " 15  InternetService_No                       4922 non-null   uint8  \n",
            " 16  Contract_Month-to-month                  4922 non-null   uint8  \n",
            " 17  Contract_One year                        4922 non-null   uint8  \n",
            " 18  Contract_Two year                        4922 non-null   uint8  \n",
            " 19  PaymentMethod_Bank transfer (automatic)  4922 non-null   uint8  \n",
            " 20  PaymentMethod_Credit card (automatic)    4922 non-null   uint8  \n",
            " 21  PaymentMethod_Electronic check           4922 non-null   uint8  \n",
            " 22  PaymentMethod_Mailed check               4922 non-null   uint8  \n",
            " 23  OnlineSecurity_1                         4922 non-null   uint8  \n",
            " 24  OnlineSecurity_No internet service       4922 non-null   uint8  \n",
            " 25  OnlineBackup_1                           4922 non-null   uint8  \n",
            " 26  OnlineBackup_No internet service         4922 non-null   uint8  \n",
            " 27  DeviceProtection_1                       4922 non-null   uint8  \n",
            " 28  DeviceProtection_No internet service     4922 non-null   uint8  \n",
            " 29  TechSupport_1                            4922 non-null   uint8  \n",
            " 30  TechSupport_No internet service          4922 non-null   uint8  \n",
            " 31  StreamingTV_1                            4922 non-null   uint8  \n",
            " 32  StreamingTV_No internet service          4922 non-null   uint8  \n",
            " 33  StreamingMovies_1                        4922 non-null   uint8  \n",
            " 34  StreamingMovies_No internet service      4922 non-null   uint8  \n",
            "dtypes: float64(3), int64(5), uint8(27)\n",
            "memory usage: 475.9 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RHXLfloTdlbh",
        "outputId": "2b7216b5-1773-4cb8-f118-0cf7abafe304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "np.where(np.isnan(X_train)) \n",
        "oversample = SMOTE()\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z_c1dorodlbk",
        "outputId": "eeaa35bd-d80d-48fe-f9f4-bb5b3f5fae1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape[1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1VTFKQHwdlbn"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "import keras\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Hi1PhpW-dlby"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "def build_model(input_dim=(35,), layers=[64,64,1], optimizer='rmsprop', dropout_rate=0.2):\n",
        "    # Instanciamos la clase del modelo secuencial\n",
        "    model = Sequential()\n",
        "    # Aplanamos los datos de entrada, sabemos que vamos a recibir imágenes\n",
        "    model.add(Flatten(input_shape=input_dim))\n",
        "    # Agregamos el resto de las capas con activación ReLU con excepción de la última\n",
        "    for l in layers[:-1]:\n",
        "        model.add(Dense(units=l, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    # Agregamos la última capa con activación softmax\n",
        "    model.add(Dense(units=layers[-1], activation='sigmoid'))\n",
        "    # Compilamos el modelo con el optimizador seleccionado\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    # Retornamos el modelo compilado\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n9vs2tVFdlb2"
      },
      "source": [
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "layers = [[512, 1],\n",
        "          [64, 32, 1],\n",
        "          [12, 8, 1],\n",
        "          [32, 32, 1]\n",
        "         ]\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "      0.001,\n",
        "      decay_steps=(X_train.shape[0]/32)*50,\n",
        "      decay_rate=1,\n",
        "      staircase=False)\n",
        "\n",
        "optimizers = [optimizers.Adam(learning_rate = lr_schedule), optimizers.SGD(momentum=0.9, nesterov=True), optimizers.RMSprop()]\n",
        "\n",
        "dropout_rates = [0.2, 0.5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b3PyQLmwdlb5",
        "outputId": "9dd63b7b-15a6-4736-c194-e481e43c669a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import itertools\n",
        "combinaciones = list(itertools.product(layers, optimizers, dropout_rates))\n",
        "combinaciones"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([512, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7fd2fa9e8940>,\n",
              "  0.2),\n",
              " ([512, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7fd2fa9e8940>,\n",
              "  0.5),\n",
              " ([512, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7fd2fa9e8978>,\n",
              "  0.2),\n",
              " ([512, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7fd2fa9e8978>,\n",
              "  0.5),\n",
              " ([512, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop at 0x7fd2fa9e8a58>,\n",
              "  0.2),\n",
              " ([512, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop at 0x7fd2fa9e8a58>,\n",
              "  0.5),\n",
              " ([64, 32, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7fd2fa9e8940>,\n",
              "  0.2),\n",
              " ([64, 32, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7fd2fa9e8940>,\n",
              "  0.5),\n",
              " ([64, 32, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7fd2fa9e8978>,\n",
              "  0.2),\n",
              " ([64, 32, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7fd2fa9e8978>,\n",
              "  0.5),\n",
              " ([64, 32, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop at 0x7fd2fa9e8a58>,\n",
              "  0.2),\n",
              " ([64, 32, 1],\n",
              "  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop at 0x7fd2fa9e8a58>,\n",
              "  0.5)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GepsBd78dlb9"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "n_splits = 3\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "verbose = 1\n",
        "\n",
        "# Instanciamos los objetos early_stopping y reduce_lr y definimos una lista de callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=0)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=20, restore_best_weights=True, verbose=0)\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "\n",
        "callbacks_list_param = callbacks_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8rDqVBm6dlb_"
      },
      "source": [
        "global_history = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y5NRt0eQdlcZ"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def make_prediction(X_test, y_test):\n",
        "\n",
        "    yprednn=model.predict(X_test)\n",
        "    yprednn=yprednn.round()\n",
        "    print('Neural Network:\\n {}\\n'.format(\n",
        "        metrics.classification_report(yprednn, y_test)))\n",
        "    print('Neural Network:\\n {}\\n'.format(\n",
        "        metrics.confusion_matrix(yprednn, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9Rrdz72Ydlcg",
        "outputId": "f3407264-a451-40ec-9ade-5220160ea951",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Importamos KFold para hacer cross-validation\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "\n",
        "# Instanciamos el objeto KFold\n",
        "kfold = KFold(n_splits=n_splits, shuffle=False)\n",
        "\n",
        "# Recorremos las combinaciones y generamos distintos modelos a ensayar\n",
        "for (layers, optimizer, dropout_rate) in combinaciones:\n",
        "    print('\\n\\nEnsayando modelo con estructura {} y optimizador {}'.format(layers, optimizer, dropout_rate))\n",
        "    \n",
        "    # Construimos el modelo\n",
        "    model = build_model(layers=layers, optimizer=optimizer, dropout_rate=dropout_rate)\n",
        "    \n",
        "    # Guardamos los pesos iniciales para usarlos en cada fold\n",
        "    model.save_weights('initial_weights.h5')\n",
        "    \n",
        "    # Generamos los sets de train y val para ensayar el modelo\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
        "        \n",
        "        # Reiniciamos los pesos del modelo\n",
        "        model.load_weights('initial_weights.h5')\n",
        "        tic = time.time()\n",
        "        # Lo entrenamos con el split de x_train e y_train correspondiente\n",
        "        history = model.fit(x=X_train[train_idx],\n",
        "                            y=y_train[train_idx],\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_train[val_idx], y_train[val_idx]),\n",
        "                            callbacks=callbacks_list_param,\n",
        "                            verbose=verbose\n",
        "                           )\n",
        "        toc=time.time()\n",
        "        n_epochs = len(history.history['loss'])\n",
        "        flod_timecost = round(toc-tic, 2)\n",
        "\n",
        "        # Evaluamos en train y en val (estos mismos valores los podemos sacar de history)\n",
        "        train_loss, train_acc = model.evaluate(X_train[train_idx], y_train[train_idx])\n",
        "        val_loss, val_acc = model.evaluate(X_train[val_idx], y_train[val_idx])\n",
        "        yprednn=model.predict(X_test)\n",
        "        yprednn=yprednn.round()\n",
        "        \n",
        "        # Agregamos esta corrida a la historia global\n",
        "        global_history.append({'fold':fold, \n",
        "                               'layers':','.join([str(elem) for elem in layers]), \n",
        "                               'optimizer':str(type(optimizer)),\n",
        "                               'dropout':dropout_rate,\n",
        "                               'batch_size': batch_size,\n",
        "                               'stoped_at_epoch': n_epochs,\n",
        "                               'train_loss':train_loss,\n",
        "                               'train_acc':train_acc,\n",
        "                               'val_loss':val_loss,\n",
        "                               'val_acc':val_acc,\n",
        "                               'time': flod_timecost,\n",
        "                               'history':history,\n",
        "                               'prediction':yprednn\n",
        "                              })"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Ensayando modelo con estructura [512, 1] y optimizador <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fd2fa9e8940>\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5094 - accuracy: 0.7943 - val_loss: 0.5603 - val_accuracy: 0.7465\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8081 - val_loss: 0.5766 - val_accuracy: 0.7254\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.8052 - val_loss: 0.5561 - val_accuracy: 0.7353\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8085 - val_loss: 0.6730 - val_accuracy: 0.6621\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8100 - val_loss: 0.5734 - val_accuracy: 0.7113\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8170 - val_loss: 0.5746 - val_accuracy: 0.7093\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.8135 - val_loss: 0.5575 - val_accuracy: 0.7175\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8226 - val_loss: 0.5371 - val_accuracy: 0.7353\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8215 - val_loss: 0.5711 - val_accuracy: 0.7055\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8180 - val_loss: 0.5911 - val_accuracy: 0.6960\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8197 - val_loss: 0.5383 - val_accuracy: 0.7345\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8242 - val_loss: 0.5761 - val_accuracy: 0.7109\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8213 - val_loss: 0.5326 - val_accuracy: 0.7304\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8261 - val_loss: 0.5184 - val_accuracy: 0.7568\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8286 - val_loss: 0.5789 - val_accuracy: 0.7159\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8267 - val_loss: 0.5525 - val_accuracy: 0.7295\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8278 - val_loss: 0.5501 - val_accuracy: 0.7295\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8319 - val_loss: 0.5476 - val_accuracy: 0.7407\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8342 - val_loss: 0.5822 - val_accuracy: 0.7308\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8321 - val_loss: 0.5224 - val_accuracy: 0.7481\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8348 - val_loss: 0.5745 - val_accuracy: 0.7188\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8317 - val_loss: 0.5980 - val_accuracy: 0.7043\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8364 - val_loss: 0.5861 - val_accuracy: 0.7159\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8416 - val_loss: 0.5169 - val_accuracy: 0.7560\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8400 - val_loss: 0.5750 - val_accuracy: 0.7130\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8397 - val_loss: 0.5295 - val_accuracy: 0.7465\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8412 - val_loss: 0.5841 - val_accuracy: 0.7130\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8464 - val_loss: 0.5813 - val_accuracy: 0.7200\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8433 - val_loss: 0.5469 - val_accuracy: 0.7370\n",
            "Epoch 30/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8478 - val_loss: 0.5620 - val_accuracy: 0.7270\n",
            "Epoch 31/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8439 - val_loss: 0.4942 - val_accuracy: 0.7709\n",
            "Epoch 32/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8513 - val_loss: 0.5900 - val_accuracy: 0.7262\n",
            "Epoch 33/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8519 - val_loss: 0.5446 - val_accuracy: 0.7486\n",
            "Epoch 34/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8472 - val_loss: 0.5962 - val_accuracy: 0.7167\n",
            "Epoch 35/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8544 - val_loss: 0.5493 - val_accuracy: 0.7386\n",
            "Epoch 36/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8540 - val_loss: 0.5669 - val_accuracy: 0.7378\n",
            "Epoch 37/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8536 - val_loss: 0.5377 - val_accuracy: 0.7523\n",
            "Epoch 38/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8544 - val_loss: 0.5847 - val_accuracy: 0.7304\n",
            "Epoch 39/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8503 - val_loss: 0.5397 - val_accuracy: 0.7535\n",
            "Epoch 40/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8542 - val_loss: 0.5698 - val_accuracy: 0.7357\n",
            "Epoch 41/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8559 - val_loss: 0.5771 - val_accuracy: 0.7341\n",
            "Epoch 42/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8553 - val_loss: 0.5304 - val_accuracy: 0.7593\n",
            "Epoch 43/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8592 - val_loss: 0.5163 - val_accuracy: 0.7651\n",
            "Epoch 44/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8557 - val_loss: 0.5089 - val_accuracy: 0.7651\n",
            "Epoch 45/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8619 - val_loss: 0.5588 - val_accuracy: 0.7440\n",
            "Epoch 46/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8615 - val_loss: 0.5562 - val_accuracy: 0.7448\n",
            "Epoch 47/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8627 - val_loss: 0.5409 - val_accuracy: 0.7498\n",
            "Epoch 48/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8629 - val_loss: 0.5009 - val_accuracy: 0.7696\n",
            "Epoch 49/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8699 - val_loss: 0.5566 - val_accuracy: 0.7469\n",
            "Epoch 50/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8648 - val_loss: 0.5233 - val_accuracy: 0.7688\n",
            "152/152 [==============================] - 0s 982us/step - loss: 0.3471 - accuracy: 0.8701\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7688\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7843 - val_loss: 0.6254 - val_accuracy: 0.7047\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8040 - val_loss: 0.6321 - val_accuracy: 0.6890\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8065 - val_loss: 0.6137 - val_accuracy: 0.7060\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8133 - val_loss: 0.5865 - val_accuracy: 0.7117\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8145 - val_loss: 0.5963 - val_accuracy: 0.7159\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8147 - val_loss: 0.6251 - val_accuracy: 0.6964\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8139 - val_loss: 0.6129 - val_accuracy: 0.7047\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8172 - val_loss: 0.5659 - val_accuracy: 0.7229\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8224 - val_loss: 0.6053 - val_accuracy: 0.7142\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8218 - val_loss: 0.5766 - val_accuracy: 0.7200\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8199 - val_loss: 0.5554 - val_accuracy: 0.7275\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8211 - val_loss: 0.6197 - val_accuracy: 0.7014\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8273 - val_loss: 0.6001 - val_accuracy: 0.7060\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8257 - val_loss: 0.5626 - val_accuracy: 0.7287\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8249 - val_loss: 0.5496 - val_accuracy: 0.7275\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8244 - val_loss: 0.5961 - val_accuracy: 0.7204\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8278 - val_loss: 0.5968 - val_accuracy: 0.7134\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8298 - val_loss: 0.5778 - val_accuracy: 0.7246\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8325 - val_loss: 0.5384 - val_accuracy: 0.7390\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8309 - val_loss: 0.5670 - val_accuracy: 0.7233\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8323 - val_loss: 0.5483 - val_accuracy: 0.7349\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8362 - val_loss: 0.5596 - val_accuracy: 0.7357\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8327 - val_loss: 0.5676 - val_accuracy: 0.7254\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8352 - val_loss: 0.5502 - val_accuracy: 0.7304\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8331 - val_loss: 0.5621 - val_accuracy: 0.7299\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.4078 - accuracy: 0.8358 - val_loss: 0.5672 - val_accuracy: 0.7295\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8333 - val_loss: 0.5667 - val_accuracy: 0.7312\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8383 - val_loss: 0.5707 - val_accuracy: 0.7208\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8402 - val_loss: 0.5637 - val_accuracy: 0.7196\n",
            "Epoch 30/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8385 - val_loss: 0.5596 - val_accuracy: 0.7291\n",
            "Epoch 31/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8406 - val_loss: 0.5590 - val_accuracy: 0.7374\n",
            "Epoch 32/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8402 - val_loss: 0.5465 - val_accuracy: 0.7370\n",
            "Epoch 33/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8433 - val_loss: 0.5304 - val_accuracy: 0.7423\n",
            "Epoch 34/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8437 - val_loss: 0.5505 - val_accuracy: 0.7328\n",
            "Epoch 35/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8470 - val_loss: 0.5840 - val_accuracy: 0.7233\n",
            "Epoch 36/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8466 - val_loss: 0.5381 - val_accuracy: 0.7390\n",
            "Epoch 37/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8462 - val_loss: 0.5674 - val_accuracy: 0.7270\n",
            "Epoch 38/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8457 - val_loss: 0.5167 - val_accuracy: 0.7560\n",
            "Epoch 39/50\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.3873 - accuracy: 0.8488 - val_loss: 0.6187 - val_accuracy: 0.7126\n",
            "Epoch 40/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8505 - val_loss: 0.5291 - val_accuracy: 0.7535\n",
            "Epoch 41/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8507 - val_loss: 0.5363 - val_accuracy: 0.7477\n",
            "Epoch 42/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8499 - val_loss: 0.5486 - val_accuracy: 0.7481\n",
            "Epoch 43/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8524 - val_loss: 0.5836 - val_accuracy: 0.7291\n",
            "Epoch 44/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8528 - val_loss: 0.5445 - val_accuracy: 0.7428\n",
            "Epoch 45/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8544 - val_loss: 0.5167 - val_accuracy: 0.7527\n",
            "Epoch 46/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8522 - val_loss: 0.5384 - val_accuracy: 0.7444\n",
            "Epoch 47/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8559 - val_loss: 0.5761 - val_accuracy: 0.7217\n",
            "Epoch 48/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8581 - val_loss: 0.5542 - val_accuracy: 0.7452\n",
            "Epoch 49/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8590 - val_loss: 0.5512 - val_accuracy: 0.7361\n",
            "Epoch 50/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8546 - val_loss: 0.5706 - val_accuracy: 0.7345\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8621\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7345\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7804 - val_loss: 0.8917 - val_accuracy: 0.5691\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8019 - val_loss: 0.8543 - val_accuracy: 0.5964\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.8017 - val_loss: 0.8454 - val_accuracy: 0.5935\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8077 - val_loss: 0.8036 - val_accuracy: 0.6133\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8096 - val_loss: 0.8103 - val_accuracy: 0.5984\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8079 - val_loss: 0.8297 - val_accuracy: 0.5997\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8104 - val_loss: 0.8561 - val_accuracy: 0.5571\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8112 - val_loss: 0.8618 - val_accuracy: 0.5616\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8096 - val_loss: 0.7377 - val_accuracy: 0.6456\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8098 - val_loss: 0.8522 - val_accuracy: 0.5616\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8098 - val_loss: 0.8666 - val_accuracy: 0.5484\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8108 - val_loss: 0.8115 - val_accuracy: 0.5608\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8091 - val_loss: 0.8243 - val_accuracy: 0.5637\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8120 - val_loss: 0.7872 - val_accuracy: 0.5844\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8151 - val_loss: 0.8130 - val_accuracy: 0.5757\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8139 - val_loss: 0.7882 - val_accuracy: 0.5947\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8129 - val_loss: 0.8291 - val_accuracy: 0.5724\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8133 - val_loss: 0.9438 - val_accuracy: 0.5058\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8133 - val_loss: 0.7672 - val_accuracy: 0.5993\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8100 - val_loss: 0.8193 - val_accuracy: 0.5687\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8127 - val_loss: 0.7667 - val_accuracy: 0.5964\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8135 - val_loss: 0.7566 - val_accuracy: 0.6034\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8122 - val_loss: 0.7277 - val_accuracy: 0.6249\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8100 - val_loss: 0.7832 - val_accuracy: 0.5914\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8153 - val_loss: 0.7613 - val_accuracy: 0.6079\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8151 - val_loss: 0.8108 - val_accuracy: 0.5691\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8151 - val_loss: 0.7299 - val_accuracy: 0.6261\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8170 - val_loss: 0.7925 - val_accuracy: 0.5794\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8184 - val_loss: 0.8062 - val_accuracy: 0.5715\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8108\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.6456\n",
            "\n",
            "\n",
            "Ensayando modelo con estructura [512, 1] y optimizador <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fd2fa9e8940>\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5085 - accuracy: 0.7878 - val_loss: 0.5834 - val_accuracy: 0.7130\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.8050 - val_loss: 0.5855 - val_accuracy: 0.7122\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8110 - val_loss: 0.5567 - val_accuracy: 0.7361\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8100 - val_loss: 0.5727 - val_accuracy: 0.7225\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8102 - val_loss: 0.5551 - val_accuracy: 0.7266\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8127 - val_loss: 0.5945 - val_accuracy: 0.7014\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8110 - val_loss: 0.5940 - val_accuracy: 0.7035\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8151 - val_loss: 0.5814 - val_accuracy: 0.7080\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8147 - val_loss: 0.5797 - val_accuracy: 0.7101\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8139 - val_loss: 0.5693 - val_accuracy: 0.7105\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8166 - val_loss: 0.5483 - val_accuracy: 0.7287\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8182 - val_loss: 0.5982 - val_accuracy: 0.7047\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8176 - val_loss: 0.5700 - val_accuracy: 0.7192\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8158 - val_loss: 0.5699 - val_accuracy: 0.7151\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8187 - val_loss: 0.5370 - val_accuracy: 0.7345\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8222 - val_loss: 0.5626 - val_accuracy: 0.7097\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8220 - val_loss: 0.5700 - val_accuracy: 0.7109\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8197 - val_loss: 0.5869 - val_accuracy: 0.7068\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8209 - val_loss: 0.5552 - val_accuracy: 0.7213\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8228 - val_loss: 0.5492 - val_accuracy: 0.7258\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8255 - val_loss: 0.5429 - val_accuracy: 0.7242\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8238 - val_loss: 0.5505 - val_accuracy: 0.7237\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8282 - val_loss: 0.5632 - val_accuracy: 0.7225\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8108\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7361\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7630 - val_loss: 0.5933 - val_accuracy: 0.7361\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.8011 - val_loss: 0.5740 - val_accuracy: 0.7407\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8062 - val_loss: 0.6085 - val_accuracy: 0.7126\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8079 - val_loss: 0.5992 - val_accuracy: 0.7101\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8083 - val_loss: 0.6266 - val_accuracy: 0.6993\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8069 - val_loss: 0.5993 - val_accuracy: 0.7051\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.8104 - val_loss: 0.5808 - val_accuracy: 0.7167\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8093 - val_loss: 0.5616 - val_accuracy: 0.7345\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8127 - val_loss: 0.5651 - val_accuracy: 0.7270\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8137 - val_loss: 0.5899 - val_accuracy: 0.7089\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8162 - val_loss: 0.6174 - val_accuracy: 0.6927\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8145 - val_loss: 0.5595 - val_accuracy: 0.7229\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8168 - val_loss: 0.5542 - val_accuracy: 0.7254\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.8137 - val_loss: 0.5563 - val_accuracy: 0.7291\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8211 - val_loss: 0.5829 - val_accuracy: 0.7171\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8182 - val_loss: 0.5763 - val_accuracy: 0.7146\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8203 - val_loss: 0.5546 - val_accuracy: 0.7295\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8215 - val_loss: 0.5940 - val_accuracy: 0.7068\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8178 - val_loss: 0.5697 - val_accuracy: 0.7200\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8230 - val_loss: 0.5532 - val_accuracy: 0.7266\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8222 - val_loss: 0.6000 - val_accuracy: 0.7035\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7901\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.7361\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7748 - val_loss: 0.9761 - val_accuracy: 0.4959\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7965 - val_loss: 0.8718 - val_accuracy: 0.5687\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8023 - val_loss: 0.9285 - val_accuracy: 0.5368\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8040 - val_loss: 0.8635 - val_accuracy: 0.5786\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8036 - val_loss: 0.8261 - val_accuracy: 0.5873\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8058 - val_loss: 0.8255 - val_accuracy: 0.5885\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.8036 - val_loss: 0.8896 - val_accuracy: 0.5620\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8054 - val_loss: 0.8354 - val_accuracy: 0.5736\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.8071 - val_loss: 0.8654 - val_accuracy: 0.5641\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8089 - val_loss: 0.8310 - val_accuracy: 0.5790\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8106 - val_loss: 0.8103 - val_accuracy: 0.5881\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8091 - val_loss: 0.8331 - val_accuracy: 0.5674\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8085 - val_loss: 0.8125 - val_accuracy: 0.5802\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8100 - val_loss: 0.7833 - val_accuracy: 0.5935\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8110 - val_loss: 0.8739 - val_accuracy: 0.5480\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8075 - val_loss: 0.8270 - val_accuracy: 0.5641\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8100 - val_loss: 0.8028 - val_accuracy: 0.5860\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8127 - val_loss: 0.8093 - val_accuracy: 0.5786\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8102 - val_loss: 0.8184 - val_accuracy: 0.5711\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8120 - val_loss: 0.8071 - val_accuracy: 0.5806\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8122 - val_loss: 0.8215 - val_accuracy: 0.5736\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8131 - val_loss: 0.8069 - val_accuracy: 0.5724\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8122 - val_loss: 0.8094 - val_accuracy: 0.5641\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8102 - val_loss: 0.7944 - val_accuracy: 0.5790\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8093 - val_loss: 0.7644 - val_accuracy: 0.5922\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.8073\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.5873\n",
            "\n",
            "\n",
            "Ensayando modelo con estructura [512, 1] y optimizador <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fd2fa9e8978>\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7692 - val_loss: 0.6749 - val_accuracy: 0.6836\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8029 - val_loss: 0.6152 - val_accuracy: 0.7179\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8089 - val_loss: 0.5799 - val_accuracy: 0.7370\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8079 - val_loss: 0.6441 - val_accuracy: 0.6923\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8100 - val_loss: 0.6003 - val_accuracy: 0.7134\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8137 - val_loss: 0.5657 - val_accuracy: 0.7312\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8087 - val_loss: 0.5603 - val_accuracy: 0.7349\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8189 - val_loss: 0.6224 - val_accuracy: 0.6964\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8195 - val_loss: 0.5721 - val_accuracy: 0.7250\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8166 - val_loss: 0.5825 - val_accuracy: 0.7225\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8191 - val_loss: 0.6117 - val_accuracy: 0.7093\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8197 - val_loss: 0.5590 - val_accuracy: 0.7320\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8211 - val_loss: 0.6043 - val_accuracy: 0.7047\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8259 - val_loss: 0.6011 - val_accuracy: 0.7026\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8234 - val_loss: 0.5956 - val_accuracy: 0.7026\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8230 - val_loss: 0.5492 - val_accuracy: 0.7312\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8246 - val_loss: 0.5760 - val_accuracy: 0.7291\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8278 - val_loss: 0.5751 - val_accuracy: 0.7287\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8269 - val_loss: 0.5264 - val_accuracy: 0.7543\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8306 - val_loss: 0.5641 - val_accuracy: 0.7242\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8315 - val_loss: 0.5323 - val_accuracy: 0.7436\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8306 - val_loss: 0.6531 - val_accuracy: 0.6844\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8317 - val_loss: 0.5851 - val_accuracy: 0.7146\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8333 - val_loss: 0.5883 - val_accuracy: 0.7146\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8344 - val_loss: 0.6200 - val_accuracy: 0.6952\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8362 - val_loss: 0.5711 - val_accuracy: 0.7155\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8356 - val_loss: 0.5205 - val_accuracy: 0.7527\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8358 - val_loss: 0.5509 - val_accuracy: 0.7395\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8408 - val_loss: 0.5878 - val_accuracy: 0.7138\n",
            "Epoch 30/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8383 - val_loss: 0.5287 - val_accuracy: 0.7622\n",
            "Epoch 31/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8381 - val_loss: 0.5169 - val_accuracy: 0.7614\n",
            "Epoch 32/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8371 - val_loss: 0.5456 - val_accuracy: 0.7407\n",
            "Epoch 33/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8406 - val_loss: 0.5322 - val_accuracy: 0.7564\n",
            "Epoch 34/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8400 - val_loss: 0.5629 - val_accuracy: 0.7221\n",
            "Epoch 35/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8418 - val_loss: 0.5442 - val_accuracy: 0.7337\n",
            "Epoch 36/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8402 - val_loss: 0.5541 - val_accuracy: 0.7237\n",
            "Epoch 37/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8404 - val_loss: 0.5733 - val_accuracy: 0.7295\n",
            "Epoch 38/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8439 - val_loss: 0.5214 - val_accuracy: 0.7597\n",
            "Epoch 39/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8457 - val_loss: 0.5400 - val_accuracy: 0.7415\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.8267\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7543\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7711 - val_loss: 0.6494 - val_accuracy: 0.7035\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8029 - val_loss: 0.6654 - val_accuracy: 0.6857\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8091 - val_loss: 0.6288 - val_accuracy: 0.7051\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8110 - val_loss: 0.6515 - val_accuracy: 0.6894\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8104 - val_loss: 0.5931 - val_accuracy: 0.7146\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8151 - val_loss: 0.6654 - val_accuracy: 0.6890\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8151 - val_loss: 0.6149 - val_accuracy: 0.7014\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8153 - val_loss: 0.6184 - val_accuracy: 0.7051\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8191 - val_loss: 0.5856 - val_accuracy: 0.7229\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8226 - val_loss: 0.5733 - val_accuracy: 0.7225\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8271 - val_loss: 0.6425 - val_accuracy: 0.6944\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8240 - val_loss: 0.5994 - val_accuracy: 0.7204\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8232 - val_loss: 0.5705 - val_accuracy: 0.7395\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8242 - val_loss: 0.5445 - val_accuracy: 0.7452\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8290 - val_loss: 0.5425 - val_accuracy: 0.7452\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8294 - val_loss: 0.6458 - val_accuracy: 0.7006\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8296 - val_loss: 0.5535 - val_accuracy: 0.7436\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8286 - val_loss: 0.6107 - val_accuracy: 0.7109\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8292 - val_loss: 0.6115 - val_accuracy: 0.7105\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8300 - val_loss: 0.5435 - val_accuracy: 0.7510\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8275 - val_loss: 0.5219 - val_accuracy: 0.7523\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8323 - val_loss: 0.5655 - val_accuracy: 0.7345\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8366 - val_loss: 0.5579 - val_accuracy: 0.7270\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8387 - val_loss: 0.5422 - val_accuracy: 0.7461\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8356 - val_loss: 0.5461 - val_accuracy: 0.7370\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8391 - val_loss: 0.6091 - val_accuracy: 0.7134\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8346 - val_loss: 0.5341 - val_accuracy: 0.7477\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8387 - val_loss: 0.5117 - val_accuracy: 0.7647\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8358 - val_loss: 0.5565 - val_accuracy: 0.7374\n",
            "Epoch 30/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8389 - val_loss: 0.5204 - val_accuracy: 0.7494\n",
            "Epoch 31/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8397 - val_loss: 0.5519 - val_accuracy: 0.7395\n",
            "Epoch 32/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8414 - val_loss: 0.6464 - val_accuracy: 0.6919\n",
            "Epoch 33/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8404 - val_loss: 0.5963 - val_accuracy: 0.7229\n",
            "Epoch 34/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8418 - val_loss: 0.5750 - val_accuracy: 0.7320\n",
            "Epoch 35/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8466 - val_loss: 0.6362 - val_accuracy: 0.7097\n",
            "Epoch 36/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8428 - val_loss: 0.6023 - val_accuracy: 0.7130\n",
            "Epoch 37/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8412 - val_loss: 0.5004 - val_accuracy: 0.7630\n",
            "Epoch 38/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8474 - val_loss: 0.5361 - val_accuracy: 0.7457\n",
            "Epoch 39/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8457 - val_loss: 0.5505 - val_accuracy: 0.7345\n",
            "Epoch 40/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8462 - val_loss: 0.5631 - val_accuracy: 0.7279\n",
            "Epoch 41/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8462 - val_loss: 0.5482 - val_accuracy: 0.7341\n",
            "Epoch 42/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8501 - val_loss: 0.5535 - val_accuracy: 0.7461\n",
            "Epoch 43/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8497 - val_loss: 0.5951 - val_accuracy: 0.7163\n",
            "Epoch 44/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8497 - val_loss: 0.5702 - val_accuracy: 0.7246\n",
            "Epoch 45/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8519 - val_loss: 0.5989 - val_accuracy: 0.7283\n",
            "Epoch 46/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8503 - val_loss: 0.5688 - val_accuracy: 0.7440\n",
            "Epoch 47/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8546 - val_loss: 0.5939 - val_accuracy: 0.7275\n",
            "Epoch 48/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8546 - val_loss: 0.5544 - val_accuracy: 0.7436\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8278\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7647\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7911 - val_loss: 0.9293 - val_accuracy: 0.5265\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8042 - val_loss: 0.7838 - val_accuracy: 0.6129\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.8067 - val_loss: 0.6836 - val_accuracy: 0.6952\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8089 - val_loss: 0.8740 - val_accuracy: 0.5674\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8073 - val_loss: 0.8647 - val_accuracy: 0.5682\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8081 - val_loss: 0.8636 - val_accuracy: 0.5728\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8085 - val_loss: 0.8559 - val_accuracy: 0.5620\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8083 - val_loss: 0.8384 - val_accuracy: 0.5720\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8133 - val_loss: 0.8288 - val_accuracy: 0.5897\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8139 - val_loss: 0.8188 - val_accuracy: 0.5976\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8137 - val_loss: 0.8374 - val_accuracy: 0.5703\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8135 - val_loss: 0.7435 - val_accuracy: 0.6385\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8122 - val_loss: 0.7970 - val_accuracy: 0.5939\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8106 - val_loss: 0.7219 - val_accuracy: 0.6468\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8106 - val_loss: 0.8360 - val_accuracy: 0.5757\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8153 - val_loss: 0.7575 - val_accuracy: 0.6245\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8135 - val_loss: 0.9597 - val_accuracy: 0.4768\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8110 - val_loss: 0.8085 - val_accuracy: 0.5902\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8139 - val_loss: 0.6725 - val_accuracy: 0.6836\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8162 - val_loss: 0.8086 - val_accuracy: 0.5649\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8145 - val_loss: 0.7820 - val_accuracy: 0.6067\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8135 - val_loss: 0.8743 - val_accuracy: 0.5521\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8145 - val_loss: 0.7073 - val_accuracy: 0.6456\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7998\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.6952\n",
            "\n",
            "\n",
            "Ensayando modelo con estructura [512, 1] y optimizador <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fd2fa9e8978>\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7789 - val_loss: 0.6074 - val_accuracy: 0.7279\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7980 - val_loss: 0.5936 - val_accuracy: 0.7196\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8021 - val_loss: 0.5767 - val_accuracy: 0.7279\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8069 - val_loss: 0.6201 - val_accuracy: 0.7031\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8098 - val_loss: 0.6074 - val_accuracy: 0.7237\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8075 - val_loss: 0.6263 - val_accuracy: 0.6989\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8077 - val_loss: 0.6372 - val_accuracy: 0.6935\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8131 - val_loss: 0.5745 - val_accuracy: 0.7246\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8145 - val_loss: 0.5819 - val_accuracy: 0.7221\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8160 - val_loss: 0.5708 - val_accuracy: 0.7221\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8174 - val_loss: 0.6109 - val_accuracy: 0.6981\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8191 - val_loss: 0.5501 - val_accuracy: 0.7407\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8166 - val_loss: 0.5905 - val_accuracy: 0.7117\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.8158 - val_loss: 0.5853 - val_accuracy: 0.7167\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8218 - val_loss: 0.5918 - val_accuracy: 0.7167\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8226 - val_loss: 0.5650 - val_accuracy: 0.7221\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8189 - val_loss: 0.5858 - val_accuracy: 0.7204\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8207 - val_loss: 0.5780 - val_accuracy: 0.7163\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8191 - val_loss: 0.5478 - val_accuracy: 0.7345\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8242 - val_loss: 0.5760 - val_accuracy: 0.7233\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8220 - val_loss: 0.5669 - val_accuracy: 0.7146\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8232 - val_loss: 0.5316 - val_accuracy: 0.7461\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8240 - val_loss: 0.5804 - val_accuracy: 0.7080\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8253 - val_loss: 0.5797 - val_accuracy: 0.7167\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8284 - val_loss: 0.5788 - val_accuracy: 0.7097\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8296 - val_loss: 0.5982 - val_accuracy: 0.7026\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8275 - val_loss: 0.5733 - val_accuracy: 0.7113\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8317 - val_loss: 0.5418 - val_accuracy: 0.7370\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8296 - val_loss: 0.5623 - val_accuracy: 0.7229\n",
            "Epoch 30/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8259 - val_loss: 0.5556 - val_accuracy: 0.7270\n",
            "Epoch 31/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8319 - val_loss: 0.5435 - val_accuracy: 0.7345\n",
            "Epoch 32/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8333 - val_loss: 0.5984 - val_accuracy: 0.7039\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8168\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7407\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7705 - val_loss: 0.5629 - val_accuracy: 0.7560\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7982 - val_loss: 0.6375 - val_accuracy: 0.7002\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.8075 - val_loss: 0.5745 - val_accuracy: 0.7324\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8058 - val_loss: 0.6319 - val_accuracy: 0.6923\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8089 - val_loss: 0.5887 - val_accuracy: 0.7258\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8145 - val_loss: 0.5888 - val_accuracy: 0.7283\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8143 - val_loss: 0.6040 - val_accuracy: 0.7213\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8114 - val_loss: 0.6101 - val_accuracy: 0.7122\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8151 - val_loss: 0.5727 - val_accuracy: 0.7337\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8147 - val_loss: 0.5800 - val_accuracy: 0.7246\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8160 - val_loss: 0.6103 - val_accuracy: 0.7093\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8151 - val_loss: 0.6226 - val_accuracy: 0.7093\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8195 - val_loss: 0.6140 - val_accuracy: 0.7122\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8224 - val_loss: 0.6018 - val_accuracy: 0.7213\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8224 - val_loss: 0.5590 - val_accuracy: 0.7312\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8215 - val_loss: 0.5688 - val_accuracy: 0.7345\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8228 - val_loss: 0.5986 - val_accuracy: 0.7258\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.4408 - accuracy: 0.8236 - val_loss: 0.5569 - val_accuracy: 0.7415\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.4380 - accuracy: 0.8240 - val_loss: 0.6042 - val_accuracy: 0.7142\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8284 - val_loss: 0.5732 - val_accuracy: 0.7250\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8263 - val_loss: 0.5664 - val_accuracy: 0.7374\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7980\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7560\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7750 - val_loss: 1.0450 - val_accuracy: 0.4673\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8005 - val_loss: 0.8237 - val_accuracy: 0.5972\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8013 - val_loss: 0.8992 - val_accuracy: 0.5562\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.8052 - val_loss: 0.7915 - val_accuracy: 0.6232\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8062 - val_loss: 0.8227 - val_accuracy: 0.5856\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8044 - val_loss: 0.9368 - val_accuracy: 0.5120\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8079 - val_loss: 0.8888 - val_accuracy: 0.5409\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8131 - val_loss: 0.8959 - val_accuracy: 0.5438\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8081 - val_loss: 0.9200 - val_accuracy: 0.4926\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8091 - val_loss: 0.8278 - val_accuracy: 0.5852\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8065 - val_loss: 0.7280 - val_accuracy: 0.6543\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8060 - val_loss: 0.7697 - val_accuracy: 0.6117\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8102 - val_loss: 0.7675 - val_accuracy: 0.6216\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8096 - val_loss: 0.8235 - val_accuracy: 0.5757\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8098 - val_loss: 0.8635 - val_accuracy: 0.5265\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8073 - val_loss: 0.8489 - val_accuracy: 0.5521\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8062 - val_loss: 0.8504 - val_accuracy: 0.5653\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8060 - val_loss: 0.8638 - val_accuracy: 0.5153\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8073 - val_loss: 0.8418 - val_accuracy: 0.5513\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8085 - val_loss: 0.8142 - val_accuracy: 0.5769\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8127 - val_loss: 0.8965 - val_accuracy: 0.4992\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8065 - val_loss: 0.7229 - val_accuracy: 0.6365\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8087 - val_loss: 0.7963 - val_accuracy: 0.5860\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8102 - val_loss: 0.7251 - val_accuracy: 0.6406\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8137 - val_loss: 0.7793 - val_accuracy: 0.5848\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8122 - val_loss: 0.7270 - val_accuracy: 0.6274\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8141 - val_loss: 0.8290 - val_accuracy: 0.5517\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8093 - val_loss: 0.7401 - val_accuracy: 0.6150\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8127 - val_loss: 0.7417 - val_accuracy: 0.6199\n",
            "Epoch 30/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8106 - val_loss: 0.8364 - val_accuracy: 0.5476\n",
            "Epoch 31/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8129 - val_loss: 0.6966 - val_accuracy: 0.6410\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8083\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6543\n",
            "\n",
            "\n",
            "Ensayando modelo con estructura [512, 1] y optimizador <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fd2fa9e8a58>\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7922 - val_loss: 0.5355 - val_accuracy: 0.7560\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8036 - val_loss: 0.5943 - val_accuracy: 0.7018\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8139 - val_loss: 0.5500 - val_accuracy: 0.7279\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.8098 - val_loss: 0.5946 - val_accuracy: 0.7022\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8112 - val_loss: 0.5128 - val_accuracy: 0.7461\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8116 - val_loss: 0.6463 - val_accuracy: 0.6671\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8168 - val_loss: 0.6266 - val_accuracy: 0.6840\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8205 - val_loss: 0.5653 - val_accuracy: 0.7105\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8184 - val_loss: 0.5694 - val_accuracy: 0.7242\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8201 - val_loss: 0.5447 - val_accuracy: 0.7320\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8234 - val_loss: 0.5851 - val_accuracy: 0.7142\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8234 - val_loss: 0.6262 - val_accuracy: 0.6890\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8249 - val_loss: 0.6494 - val_accuracy: 0.6948\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8282 - val_loss: 0.5290 - val_accuracy: 0.7440\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8232 - val_loss: 0.4983 - val_accuracy: 0.7659\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8311 - val_loss: 0.5195 - val_accuracy: 0.7618\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8348 - val_loss: 0.5458 - val_accuracy: 0.7333\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8304 - val_loss: 0.5931 - val_accuracy: 0.7051\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8368 - val_loss: 0.6075 - val_accuracy: 0.7018\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8366 - val_loss: 0.5410 - val_accuracy: 0.7291\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8393 - val_loss: 0.5254 - val_accuracy: 0.7531\n",
            "152/152 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8011\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7560\n",
            "Epoch 1/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7870 - val_loss: 0.6475 - val_accuracy: 0.6948\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8071 - val_loss: 0.7031 - val_accuracy: 0.6538\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8075 - val_loss: 0.5709 - val_accuracy: 0.7188\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8071 - val_loss: 0.5614 - val_accuracy: 0.7184\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8153 - val_loss: 0.6660 - val_accuracy: 0.6890\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8114 - val_loss: 0.6055 - val_accuracy: 0.7043\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8166 - val_loss: 0.5679 - val_accuracy: 0.7175\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8195 - val_loss: 0.5170 - val_accuracy: 0.7428\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8203 - val_loss: 0.5541 - val_accuracy: 0.7192\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8232 - val_loss: 0.5812 - val_accuracy: 0.7084\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8240 - val_loss: 0.5676 - val_accuracy: 0.7357\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8275 - val_loss: 0.5190 - val_accuracy: 0.7506\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8280 - val_loss: 0.6018 - val_accuracy: 0.7204\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8284 - val_loss: 0.6379 - val_accuracy: 0.6919\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8311 - val_loss: 0.6293 - val_accuracy: 0.7039\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8280 - val_loss: 0.5684 - val_accuracy: 0.7415\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8335 - val_loss: 0.5428 - val_accuracy: 0.7378\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8366 - val_loss: 0.5443 - val_accuracy: 0.7506\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8362 - val_loss: 0.5634 - val_accuracy: 0.7179\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8356 - val_loss: 0.5588 - val_accuracy: 0.7382\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8389 - val_loss: 0.5507 - val_accuracy: 0.7337\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8402 - val_loss: 0.6052 - val_accuracy: 0.7242\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8410 - val_loss: 0.5265 - val_accuracy: 0.7527\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8387 - val_loss: 0.5389 - val_accuracy: 0.7564\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8447 - val_loss: 0.4846 - val_accuracy: 0.7676\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8431"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S9IQwVexdlc0"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(global_history)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vzo-6Rg9dlc8"
      },
      "source": [
        "def plot_history(name, history, legend, plot_val=True):\n",
        "    fig, ax = plt.subplots(1,2,figsize=(14,6))\n",
        "    fig.suptitle(name)\n",
        "    \n",
        "    if not isinstance(history, list):\n",
        "        history = [history]\n",
        "        \n",
        "    for h in history:\n",
        "        acc = h.history['accuracy']\n",
        "        loss = h.history['loss']\n",
        "        if plot_val:\n",
        "            val_loss = h.history['val_loss']\n",
        "            val_acc = h.history['val_accuracy']\n",
        "        epochs = range(1, len(acc) + 1)\n",
        "\n",
        "        ax[0].set_title('Loss')\n",
        "        ax[0].set_xticks(ticks=epochs)\n",
        "        ax[0].set_ylabel('Loss')\n",
        "        \n",
        "        ax[0].plot(epochs, loss)\n",
        "        if plot_val:\n",
        "            ax[0].plot(epochs, val_loss)\n",
        "            \n",
        "        ax[1].set_title('Accuracy')\n",
        "        ax[1].set_xticks(ticks=list(epochs))\n",
        "        ax[1].set_xlabel('Epochs')\n",
        "        ax[1].set_ylabel('Accuracy')\n",
        "        ax[1].plot(epochs, acc)\n",
        "        if plot_val:\n",
        "            ax[1].plot(epochs, val_acc)\n",
        "        \n",
        "    ax[0].legend([l+' loss' for l in legend])\n",
        "    ax[1].legend([l+' accuracy' for l in legend])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na0OvmJfdldH"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def make_prediction(X_test, y_test):\n",
        "\n",
        "    yprednn=model.predict(X_test)\n",
        "    yprednn=yprednn.round()\n",
        "    print('Neural Network:\\n {}\\n'.format(\n",
        "        metrics.classification_report(yprednn, y_test)))\n",
        "    print('Neural Network:\\n {}\\n'.format(\n",
        "        metrics.confusion_matrix(yprednn, y_test)))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z-qg0mnidldR"
      },
      "source": [
        "for history in global_history:\n",
        "    plot_history(history['layers'], history['history'], legend=['train', 'val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_1_hbnKhdldd"
      },
      "source": [
        "for history in global_history:\n",
        "    print(history['layers'], history['optimizer'])\n",
        "    print('Neural Network:\\n {}\\n'.format(\n",
        "        metrics.classification_report(history['prediction'], y_test)))\n",
        "    print('Neural Network:\\n {}\\n'.format(\n",
        "        metrics.confusion_matrix(history['prediction'], y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YDZDJFnddldn"
      },
      "source": [
        "import pandas as pd\n",
        "df_history = pd.DataFrame(global_history)\n",
        "df_history.sort_values(by='val_acc', ascending=False,inplace=True)\n",
        "\n",
        "df_history.groupby(['layers','optimizer', 'dropout', 'batch_size']).mean().sort_values(by='val_acc', ascending=False).drop(['fold'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty3h2O6tdldt"
      },
      "source": [
        "# Nos quedamos con las redes [64, 32, 1] y [512,1] ambas con RMSprop y 0.2 de Drop Out, y las probamos para más epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "18Vd_n7tdldt"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(X_train.shape[1]))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_split=0.3,\n",
        "                    batch_size=32, epochs=500)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w4XtIv7Odld9"
      },
      "source": [
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Modelo de base')\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.xticks(ticks=epochs)\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training loss', 'Validation loss'])\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.xticks(ticks=list(epochs))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training accuracy', 'Validation accuracy']);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JugKD5eKdleG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eYvNYDfZdleM"
      },
      "source": [
        "yprednn=model.predict(X_test)\n",
        "yprednn=yprednn.round()\n",
        "print('Neural Network:\\n {}\\n'.format(\n",
        "    metrics.classification_report(yprednn, y_test)))\n",
        "print('Neural Network:\\n {}\\n'.format(\n",
        "    metrics.confusion_matrix(yprednn, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BNBqABxxdleS"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
        "cm = confusion_matrix(y_true=y_test, y_pred=yprednn)\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    \n",
        "plot_confusion_matrix(cm=cm, classes=['Yes', 'No'], title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go0iSby0dleZ"
      },
      "source": [
        "# # Ahora probamos con la red de [512, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9MSad3o2dlea"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(X_train.shape[1]))\n",
        "model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_split=0.3,\n",
        "                    batch_size=32, epochs=500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GhlGI80Sdleg"
      },
      "source": [
        "yprednn=model.predict(X_test)\n",
        "yprednn=yprednn.round()\n",
        "print('Neural Network:\\n {}\\n'.format(\n",
        "    metrics.classification_report(yprednn, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gidb_P0vdlel"
      },
      "source": [
        "cm = confusion_matrix(y_true=y_test, y_pred=yprednn)\n",
        "plot_confusion_matrix(cm=cm, classes=['Yes', 'No'], title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x47czRAtdleq"
      },
      "source": [
        "# # Vemos que performa mejor la red con una estructura [64,32,1]"
      ]
    }
  ]
}