{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "## Columns:\n",
    "\n",
    "**Customer ID:** Whether the customer is a male or a female\n",
    "\n",
    "**SeniorCitizen:** Whether the customer is a senior citizen or not (1, 0)\n",
    "\n",
    "**checkPartner:** Whether the customer has a partner or not (Yes, No)\n",
    "\n",
    "**checkDependents:** Whether the customer has dependents or not (Yes, No)\n",
    "\n",
    "**tenure:** Number of months the customer has stayed with the company\n",
    "\n",
    "**checkPhoneService:** Whether the customer has a phone service or not (Yes, No)\n",
    "\n",
    "**text_formatMultipleLines:** Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
    "\n",
    "**text_formatInternetService:** Customer’s internet service provider (DSL, Fiber optic, No)\n",
    "\n",
    "**text_formatOnlineSecurity:** Whether the customer has online security or not (Yes, No, No internet service)\n",
    "\n",
    "**text_formatOnlineBackup:** Whether the customer has online backup or not (Yes, No, No internet service)\n",
    "\n",
    "**text_formatDeviceProtection:** Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "\n",
    "**text_formatTechSupport:** Whether the customer has tech support or not (Yes, No, No internet service)\n",
    "\n",
    "**text_formatStreamingTV:** Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "\n",
    "**text_formatStreamingMovies:** Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
    "\n",
    "**text_formatContract:** The contract term of the customer (Month-to-month, One year, Two year)\n",
    "\n",
    "**checkPaperlessBilling:** Whether the customer has paperless billing or not (Yes, No)\n",
    "\n",
    "**text_formatPaymentMethod:** The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
    "\n",
    "**MonthlyCharges:** The amount charged to the customer monthly\n",
    "\n",
    "**TotalCharges:** The total amount charged to the customer\n",
    "\n",
    "**checkChurn:** Whether the customer churned or not (Yes or No)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Imports:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Cargar dataset:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('DF_Cols.csv')\n",
    "X_train.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "y_train = pd.read_csv('DF_Target.csv')\n",
    "y_train = y_train.Churn_Yes\n",
    "\n",
    "X_test = pd.read_csv('DF_Cols_Test.csv')\n",
    "X_test.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "y_test = pd.read_csv('DF_Target_Test.csv')\n",
    "y_test = y_test.Churn_Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (5282, 30)\n",
      "y_train (5282,)\n",
      "X_test (1761, 30)\n",
      "y_test (1761,)\n",
      "··················\n",
      "Values target train:\n",
      "0    0.73457\n",
      "1    0.26543\n",
      "Name: Churn_Yes, dtype: float64\n",
      "··················\n",
      "Values target test:\n",
      "0    0.73481\n",
      "1    0.26519\n",
      "Name: Churn_Yes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)\n",
    "print('··················')\n",
    "print('Values target train:')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('··················')\n",
    "print('Values target test:')\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una instancia nueva de X_train sin modificar\n",
    "X_orig = X_train.copy()\n",
    "\n",
    "# Escalo los datos de train y test\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos un modelo de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nNlzt9OnXDT"
   },
   "source": [
    "## 3. Exploracion de modelos\n",
    "\n",
    "vamos a definir una función que nos permita instanciar un modelo secuencial a partir de los parámetros que recibe y configurar la **arquitectura** (cantidad de capas, cantidad de neuronas por capa, valor de drop out), el tamaño de los datos de entrada y el **optimizador**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_inicial = X_train.shape[1]\n",
    "input_inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5282, 2), (1761, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=(X_train.shape[1],), layers=[64,64,2], optimizer='rmsprop', dropout_rate=0.25):\n",
    "    # Instanciamos la clase del modelo secuencial\n",
    "    model = Sequential()\n",
    "    # Aplanamos los datos de entrada, sabemos que vamos a recibir imágenes\n",
    "    model.add(Dense(layers[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Agregamos el resto de las capas con activación ReLU con excepción de la última\n",
    "    for l in layers[1:-1]:\n",
    "        model.add(Dense(units=l, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    # Agregamos la última capa con activación softmax\n",
    "    model.add(Dense(units=layers[-1], activation='softmax'))\n",
    "    # Compilamos el modelo con el optimizador seleccionado\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Retornamos el modelo compilado\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos un modelo de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(layers=[32, 32, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                992       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,114\n",
      "Trainable params: 2,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# Definimos la \"grilla\" de parámetros que vamos a explorar\n",
    "layers = [[32, 32, 2],\n",
    "          [64, 2],\n",
    "          [128, 2]\n",
    "         ]\n",
    "\n",
    "batch_sizes = [256]\n",
    "\n",
    "optimizers = [optimizers.Adam(), optimizers.SGD(momentum=0.9, nesterov=True), optimizers.RMSprop()]\n",
    "\n",
    "dropout_rates = [0, 0.1, 0.25, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos generar las combinaciones entre las posibilidades de ambos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "combinaciones = list(itertools.product(layers, optimizers, dropout_rates, batch_sizes))\n",
    "len(combinaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([32, 32, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0, 256),\n",
       " ([32, 32, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.1, 256),\n",
       " ([32, 32, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.25, 256),\n",
       " ([32, 32, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.5, 256),\n",
       " ([32, 32, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0, 256),\n",
       " ([32, 32, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.1, 256),\n",
       " ([32, 32, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.25, 256),\n",
       " ([32, 32, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.5, 256),\n",
       " ([32, 32, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0, 256),\n",
       " ([32, 32, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.1, 256),\n",
       " ([32, 32, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.25, 256),\n",
       " ([32, 32, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.5, 256),\n",
       " ([64, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0, 256),\n",
       " ([64, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.1, 256),\n",
       " ([64, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.25, 256),\n",
       " ([64, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.5, 256),\n",
       " ([64, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0, 256),\n",
       " ([64, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.1, 256),\n",
       " ([64, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.25, 256),\n",
       " ([64, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.5, 256),\n",
       " ([64, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0, 256),\n",
       " ([64, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.1, 256),\n",
       " ([64, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.25, 256),\n",
       " ([64, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.5, 256),\n",
       " ([128, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0, 256),\n",
       " ([128, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.1, 256),\n",
       " ([128, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.25, 256),\n",
       " ([128, 2], <keras.optimizers.Adam at 0x1661f67c848>, 0.5, 256),\n",
       " ([128, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0, 256),\n",
       " ([128, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.1, 256),\n",
       " ([128, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.25, 256),\n",
       " ([128, 2], <keras.optimizers.SGD at 0x1661f70ea48>, 0.5, 256),\n",
       " ([128, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0, 256),\n",
       " ([128, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.1, 256),\n",
       " ([128, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.25, 256),\n",
       " ([128, 2], <keras.optimizers.RMSprop at 0x1661f72bf48>, 0.5, 256)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos variables estáticas\n",
    "n_splits = 3\n",
    "epochs = 300\n",
    "verbose = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos los objetos early_stopping y reduce_lr y definimos una lista de callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=0)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, restore_best_weights=True, verbose=0)\n",
    "callbacks_list = [reduce_lr, early_stopping]\n",
    "\n",
    "callbacks_list_param = callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista vacía para ir guardando los entrenamientos\n",
    "global_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 18us/step\n",
      "1761/1761 [==============================] - 0s 19us/step\n",
      "accuracy:  0.7859170925610448\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 36us/step\n",
      "1761/1761 [==============================] - 0s 22us/step\n",
      "accuracy:  0.7796706416808632\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 24us/step\n",
      "1760/1760 [==============================] - 0s 19us/step\n",
      "accuracy:  0.7773992049971608\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 22us/step\n",
      "1761/1761 [==============================] - 0s 20us/step\n",
      "accuracy:  0.7779670641680864\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 30us/step\n",
      "1761/1761 [==============================] - 0s 20us/step\n",
      "accuracy:  0.7808063600227144\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 31us/step\n",
      "1760/1760 [==============================] - 0s 34us/step\n",
      "accuracy:  0.7830777967064169\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 25us/step\n",
      "1761/1761 [==============================] - 0s 30us/step\n",
      "accuracy:  0.771152754116979\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 25us/step\n",
      "1761/1761 [==============================] - 0s 29us/step\n",
      "accuracy:  0.75809199318569\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 20us/step\n",
      "1760/1760 [==============================] - 0s 24us/step\n",
      "accuracy:  0.7688813174332766\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 29us/step\n",
      "1761/1761 [==============================] - 0s 23us/step\n",
      "accuracy:  0.7450312322544009\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 27us/step\n",
      "accuracy:  0.7421919363997729\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 20us/step\n",
      "1760/1760 [==============================] - 0s 24us/step\n",
      "accuracy:  0.7563884156729132\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 18us/step\n",
      "1761/1761 [==============================] - 0s 20us/step\n",
      "accuracy:  0.7904599659284497\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 19us/step\n",
      "1761/1761 [==============================] - 0s 21us/step\n",
      "accuracy:  0.78137421919364\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 19us/step\n",
      "1760/1760 [==============================] - 0s 22us/step\n",
      "accuracy:  0.7853492333901193\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 28us/step\n",
      "1761/1761 [==============================] - 0s 27us/step\n",
      "accuracy:  0.7751277683134583\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 23us/step\n",
      "accuracy:  0.7739920499716071\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 20us/step\n",
      "1760/1760 [==============================] - 0s 22us/step\n",
      "accuracy:  0.7808063600227144\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 43us/step\n",
      "1761/1761 [==============================] - 0s 21us/step\n",
      "accuracy:  0.7626348665530949\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 24us/step\n",
      "accuracy:  0.7654741624077229\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 26us/step\n",
      "1760/1760 [==============================] - 0s 29us/step\n",
      "accuracy:  0.7717206132879046\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 20us/step\n",
      "accuracy:  0.7552526973310619\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 42us/step\n",
      "1761/1761 [==============================] - 0s 38us/step\n",
      "accuracy:  0.7336740488358887\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 26us/step\n",
      "1760/1760 [==============================] - 0s 19us/step\n",
      "accuracy:  0.7336740488358887\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 24us/step\n",
      "accuracy:  0.7864849517319704\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 38us/step\n",
      "1761/1761 [==============================] - 0s 19us/step\n",
      "accuracy:  0.7597955706984668\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 48us/step\n",
      "1760/1760 [==============================] - 0s 26us/step\n",
      "accuracy:  0.75809199318569\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 21us/step\n",
      "1761/1761 [==============================] - 0s 22us/step\n",
      "accuracy:  0.7830777967064169\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 23us/step\n",
      "accuracy:  0.7791027825099376\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 45us/step\n",
      "1760/1760 [==============================] - 0s 42us/step\n",
      "accuracy:  0.7819420783645656\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 36us/step\n",
      "1761/1761 [==============================] - 0s 21us/step\n",
      "accuracy:  0.7512776831345827\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 28us/step\n",
      "accuracy:  0.7473026689381034\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 25us/step\n",
      "1760/1760 [==============================] - 0s 25us/step\n",
      "accuracy:  0.7501419647927314\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [32, 32, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 24us/step\n",
      "1761/1761 [==============================] - 0s 23us/step\n",
      "accuracy:  0.7558205565019875\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 69us/step\n",
      "1761/1761 [==============================] - 0s 36us/step\n",
      "accuracy:  0.7535491198182851\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 26us/step\n",
      "1760/1760 [==============================] - 0s 22us/step\n",
      "accuracy:  0.7626348665530949\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 17us/step\n",
      "accuracy:  0.7762634866553095\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 18us/step\n",
      "1761/1761 [==============================] - 0s 19us/step\n",
      "accuracy:  0.7694491766042022\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 24us/step\n",
      "1760/1760 [==============================] - 0s 27us/step\n",
      "accuracy:  0.771152754116979\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 24us/step\n",
      "1761/1761 [==============================] - 0s 18us/step\n",
      "accuracy:  0.7898921067575241\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 13us/step\n",
      "1761/1761 [==============================] - 0s 14us/step\n",
      "accuracy:  0.7819420783645656\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 13us/step\n",
      "1760/1760 [==============================] - 0s 14us/step\n",
      "accuracy:  0.7853492333901193\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 13us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7893242475865985\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7802385008517888\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 13us/step\n",
      "1760/1760 [==============================] - 0s 16us/step\n",
      "accuracy:  0.7830777967064169\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7734241908006815\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 16us/step\n",
      "accuracy:  0.7722884724588303\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 18us/step\n",
      "1760/1760 [==============================] - 0s 16us/step\n",
      "accuracy:  0.7717206132879046\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 16us/step\n",
      "1761/1761 [==============================] - 0s 16us/step\n",
      "accuracy:  0.44804088586030666\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 23us/step\n",
      "1761/1761 [==============================] - 0s 23us/step\n",
      "accuracy:  0.44804088586030666\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 13us/step\n",
      "1760/1760 [==============================] - 0s 14us/step\n",
      "accuracy:  0.44804088586030666\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 16us/step\n",
      "1761/1761 [==============================] - 0s 16us/step\n",
      "accuracy:  0.5457126632595116\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 22us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.5457126632595116\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 14us/step\n",
      "1760/1760 [==============================] - 0s 15us/step\n",
      "accuracy:  0.5457126632595116\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 21us/step\n",
      "1761/1761 [==============================] - 0s 24us/step\n",
      "accuracy:  0.3679727427597956\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 13us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.3679727427597956\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 14us/step\n",
      "1760/1760 [==============================] - 0s 15us/step\n",
      "accuracy:  0.3679727427597956\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 27us/step\n",
      "1761/1761 [==============================] - 0s 27us/step\n",
      "accuracy:  0.5167518455423055\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.5167518455423055\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 16us/step\n",
      "1760/1760 [==============================] - 0s 17us/step\n",
      "accuracy:  0.5167518455423055\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 12us/step\n",
      "1761/1761 [==============================] - 0s 14us/step\n",
      "accuracy:  0.7671777399204998\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 12us/step\n",
      "1761/1761 [==============================] - 0s 13us/step\n",
      "accuracy:  0.7739920499716071\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 16us/step\n",
      "1760/1760 [==============================] - 0s 16us/step\n",
      "accuracy:  0.7734241908006815\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 14us/step\n",
      "accuracy:  0.7876206700738216\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7887563884156729\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 16us/step\n",
      "1760/1760 [==============================] - 0s 17us/step\n",
      "accuracy:  0.7859170925610448\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 13us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7773992049971608\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 16us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7734241908006815\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 15us/step\n",
      "1760/1760 [==============================] - 0s 14us/step\n",
      "accuracy:  0.7762634866553095\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [64, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 17us/step\n",
      "accuracy:  0.760931289040318\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 16us/step\n",
      "accuracy:  0.7558205565019875\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 14us/step\n",
      "1760/1760 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7603634298693924\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 15us/step\n",
      "1761/1761 [==============================] - 0s 16us/step\n",
      "accuracy:  0.7876206700738216\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 13us/step\n",
      "1761/1761 [==============================] - 0s 14us/step\n",
      "accuracy:  0.7864849517319704\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 13us/step\n",
      "1760/1760 [==============================] - 0s 14us/step\n",
      "accuracy:  0.7802385008517888\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 15us/step\n",
      "accuracy:  0.7825099375354913\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 14us/step\n",
      "1761/1761 [==============================] - 0s 17us/step\n",
      "accuracy:  0.6626916524701874\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 14us/step\n",
      "1760/1760 [==============================] - 0s 15us/step\n",
      "accuracy:  0.6490630323679727\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 20us/step\n",
      "1761/1761 [==============================] - 0s 18us/step\n",
      "accuracy:  0.45258375922771155\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 23us/step\n",
      "1761/1761 [==============================] - 0s 25us/step\n",
      "accuracy:  0.4440658716638274\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 27us/step\n",
      "1760/1760 [==============================] - 0s 38us/step\n",
      "accuracy:  0.4338444065871664\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.Adam object at 0x000001661F67C848> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 24us/step\n",
      "1761/1761 [==============================] - 0s 25us/step\n",
      "accuracy:  0.7251561612720046\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 19us/step\n",
      "1761/1761 [==============================] - 0s 18us/step\n",
      "accuracy:  0.6871095968199886\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 20us/step\n",
      "1760/1760 [==============================] - 0s 25us/step\n",
      "accuracy:  0.6888131743327655\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 24us/step\n",
      "1761/1761 [==============================] - 0s 22us/step\n",
      "accuracy:  0.5826235093696763\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 33us/step\n",
      "1761/1761 [==============================] - 0s 26us/step\n",
      "accuracy:  0.5826235093696763\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 19us/step\n",
      "1760/1760 [==============================] - 0s 18us/step\n",
      "accuracy:  0.5826235093696763\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 21us/step\n",
      "1761/1761 [==============================] - 0s 23us/step\n",
      "accuracy:  0.4298693923906871\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 37us/step\n",
      "1761/1761 [==============================] - 0s 44us/step\n",
      "accuracy:  0.4298693923906871\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 25us/step\n",
      "1760/1760 [==============================] - 0s 23us/step\n",
      "accuracy:  0.4298693923906871\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 22us/step\n",
      "1761/1761 [==============================] - 0s 18us/step\n",
      "accuracy:  0.4332765474162408\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 22us/step\n",
      "1761/1761 [==============================] - 0s 18us/step\n",
      "accuracy:  0.4332765474162408\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 19us/step\n",
      "1760/1760 [==============================] - 0s 18us/step\n",
      "accuracy:  0.4332765474162408\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.SGD object at 0x000001661F70EA48> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 18us/step\n",
      "1761/1761 [==============================] - 0s 19us/step\n",
      "accuracy:  0.5354911981828506\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 18us/step\n",
      "1761/1761 [==============================] - 0s 19us/step\n",
      "accuracy:  0.5354911981828506\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 20us/step\n",
      "1760/1760 [==============================] - 0s 23us/step\n",
      "accuracy:  0.5354911981828506\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 22us/step\n",
      "1761/1761 [==============================] - 0s 20us/step\n",
      "accuracy:  0.7978421351504826\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 18us/step\n",
      "1761/1761 [==============================] - 0s 19us/step\n",
      "accuracy:  0.7967064168086314\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 38us/step\n",
      "1760/1760 [==============================] - 0s 26us/step\n",
      "accuracy:  0.7955706984667802\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.1\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 25us/step\n",
      "1761/1761 [==============================] - 0s 39us/step\n",
      "accuracy:  0.7853492333901193\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 17us/step\n",
      "1761/1761 [==============================] - 0s 16us/step\n",
      "accuracy:  0.7893242475865985\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 28us/step\n",
      "1760/1760 [==============================] - 0s 24us/step\n",
      "accuracy:  0.7904599659284497\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.25\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 21us/step\n",
      "1761/1761 [==============================] - 0s 22us/step\n",
      "accuracy:  0.7961385576377058\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 24us/step\n",
      "1761/1761 [==============================] - 0s 21us/step\n",
      "accuracy:  0.7915956842703009\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 22us/step\n",
      "1760/1760 [==============================] - 0s 23us/step\n",
      "accuracy:  0.794434980124929\n",
      "\n",
      "\n",
      "Ensayando modelo con estructura [128, 2], optimizador <keras.optimizers.RMSprop object at 0x000001661F72BF48> y dropout rate 0.5\n",
      "[1761 1762 1763 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 31us/step\n",
      "1761/1761 [==============================] - 0s 28us/step\n",
      "accuracy:  0.797274275979557\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "3521/3521 [==============================] - 0s 22us/step\n",
      "1761/1761 [==============================] - 0s 24us/step\n",
      "accuracy:  0.7967064168086314\n",
      "[   0    1    2 ... 3519 3520 3521]\n",
      "3522/3522 [==============================] - 0s 21us/step\n",
      "1760/1760 [==============================] - 0s 20us/step\n",
      "accuracy:  0.7955706984667802\n"
     ]
    }
   ],
   "source": [
    "# Importamos KFold para hacer cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "# Instanciamos el objeto KFold\n",
    "kfold = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "# Recorremos las combinaciones y generamos distintos modelos a ensayar\n",
    "for (layers, optimizer, dropout_rate, batch_size) in combinaciones:\n",
    "    print('\\n\\nEnsayando modelo con estructura {}, optimizador {} y dropout rate {}'.format(layers, optimizer, dropout_rate))\n",
    "    \n",
    "    # Construimos el modelo\n",
    "    model = build_model(layers=layers, optimizer=optimizer, dropout_rate=dropout_rate)\n",
    "    \n",
    "    # Guardamos los pesos iniciales para usarlos en cada fold\n",
    "    model.save_weights('initial_weights.h5')\n",
    "    \n",
    "    # Generamos los sets de train y val para ensayar el modelo\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        \n",
    "        # Reiniciamos los pesos del modelo\n",
    "        model.load_weights('initial_weights.h5')\n",
    "        \n",
    "        # Lo entrenamos con el split de X_train e y_train correspondiente\n",
    "        print(train_idx)\n",
    "        tic=time.time()\n",
    "        history = model.fit(x=X_train[train_idx],\n",
    "                            y=y_train[train_idx],\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_train[val_idx], y_train[val_idx]),\n",
    "                            verbose=verbose,\n",
    "                            callbacks=callbacks_list_param,\n",
    "                           )\n",
    "        toc=time.time()\n",
    "             \n",
    "        n_epochs = len(history.history['loss'])\n",
    "        \n",
    "        flod_timecost = round(toc-tic, 2)\n",
    "        # Evaluamos en train y en val (estos mismos valores los podemos sacar de history)\n",
    "        train_loss, train_acc = model.evaluate(X_train[train_idx], y_train[train_idx])\n",
    "        val_loss, val_acc = model.evaluate(X_train[val_idx], y_train[val_idx])\n",
    "        \n",
    "        yprednn=model.predict(X_test)\n",
    "        yprednn=yprednn.round()\n",
    " \n",
    "\n",
    "        #print('accuracy: ', yprednn)\n",
    "        acc_pred = accuracy_score(np.argmax(y_test, axis=1), np.argmax(yprednn, axis=1))\n",
    "        print('accuracy: ', acc_pred)\n",
    "        \n",
    "        # Agregamos esta corrida a la historia global\n",
    "        global_history.append({'fold':fold, \n",
    "                               'layers':','.join([str(elem) for elem in layers]), \n",
    "                               'optimizer':str(type(optimizer)),\n",
    "                               'dropout':dropout_rate,\n",
    "                               'batch_size': batch_size,\n",
    "                               'stoped_at_epoch': n_epochs,\n",
    "                               'train_loss':train_loss,\n",
    "                               'train_acc':train_acc,\n",
    "                               'val_loss':val_loss,\n",
    "                               'val_acc':val_acc,\n",
    "                               'acc_pred':acc_pred,\n",
    "                               'time': flod_timecost,\n",
    "                               'history':history, \n",
    "                               'predict': yprednn\n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_history = pd.DataFrame(global_history)\n",
    "df_history.sort_values(by='val_loss', ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>layers</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>stoped_at_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>acc_pred</th>\n",
       "      <th>time</th>\n",
       "      <th>history</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32,32,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256</td>\n",
       "      <td>19</td>\n",
       "      <td>0.407172</td>\n",
       "      <td>0.807441</td>\n",
       "      <td>0.421311</td>\n",
       "      <td>0.805792</td>\n",
       "      <td>0.785917</td>\n",
       "      <td>1.28</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>128,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
       "      <td>0.10</td>\n",
       "      <td>256</td>\n",
       "      <td>300</td>\n",
       "      <td>0.423586</td>\n",
       "      <td>0.796365</td>\n",
       "      <td>0.422230</td>\n",
       "      <td>0.809767</td>\n",
       "      <td>0.782510</td>\n",
       "      <td>13.29</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>128,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256</td>\n",
       "      <td>300</td>\n",
       "      <td>0.427701</td>\n",
       "      <td>0.797217</td>\n",
       "      <td>0.423438</td>\n",
       "      <td>0.813742</td>\n",
       "      <td>0.797842</td>\n",
       "      <td>9.64</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>32,32,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.SGD'&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>0.414693</td>\n",
       "      <td>0.802613</td>\n",
       "      <td>0.424286</td>\n",
       "      <td>0.808064</td>\n",
       "      <td>0.790460</td>\n",
       "      <td>1.09</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>128,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>0.10</td>\n",
       "      <td>256</td>\n",
       "      <td>300</td>\n",
       "      <td>0.424164</td>\n",
       "      <td>0.794093</td>\n",
       "      <td>0.425792</td>\n",
       "      <td>0.805224</td>\n",
       "      <td>0.785349</td>\n",
       "      <td>21.34</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>32,32,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>0.408177</td>\n",
       "      <td>0.806873</td>\n",
       "      <td>0.426708</td>\n",
       "      <td>0.802953</td>\n",
       "      <td>0.786485</td>\n",
       "      <td>1.04</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>128,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>0.25</td>\n",
       "      <td>256</td>\n",
       "      <td>300</td>\n",
       "      <td>0.431711</td>\n",
       "      <td>0.802329</td>\n",
       "      <td>0.428115</td>\n",
       "      <td>0.810903</td>\n",
       "      <td>0.796139</td>\n",
       "      <td>15.97</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>128,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>0.50</td>\n",
       "      <td>256</td>\n",
       "      <td>300</td>\n",
       "      <td>0.430745</td>\n",
       "      <td>0.795229</td>\n",
       "      <td>0.429373</td>\n",
       "      <td>0.804656</td>\n",
       "      <td>0.797274</td>\n",
       "      <td>14.30</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>128,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256</td>\n",
       "      <td>300</td>\n",
       "      <td>0.428388</td>\n",
       "      <td>0.797785</td>\n",
       "      <td>0.430013</td>\n",
       "      <td>0.797842</td>\n",
       "      <td>0.787621</td>\n",
       "      <td>10.23</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>64,2</td>\n",
       "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
       "      <td>0.25</td>\n",
       "      <td>256</td>\n",
       "      <td>300</td>\n",
       "      <td>0.439105</td>\n",
       "      <td>0.785004</td>\n",
       "      <td>0.431162</td>\n",
       "      <td>0.805792</td>\n",
       "      <td>0.789324</td>\n",
       "      <td>9.87</td>\n",
       "      <td>&lt;keras.callbacks.callbacks.History object at 0...</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold   layers                           optimizer  dropout  batch_size  \\\n",
       "0       0  32,32,2     <class 'keras.optimizers.Adam'>     0.00         256   \n",
       "75      0    128,2     <class 'keras.optimizers.Adam'>     0.10         256   \n",
       "96      0    128,2  <class 'keras.optimizers.RMSprop'>     0.00         256   \n",
       "12      0  32,32,2      <class 'keras.optimizers.SGD'>     0.00         256   \n",
       "99      0    128,2  <class 'keras.optimizers.RMSprop'>     0.10         256   \n",
       "24      0  32,32,2  <class 'keras.optimizers.RMSprop'>     0.00         256   \n",
       "102     0    128,2  <class 'keras.optimizers.RMSprop'>     0.25         256   \n",
       "105     0    128,2  <class 'keras.optimizers.RMSprop'>     0.50         256   \n",
       "72      0    128,2     <class 'keras.optimizers.Adam'>     0.00         256   \n",
       "42      0     64,2     <class 'keras.optimizers.Adam'>     0.25         256   \n",
       "\n",
       "     stoped_at_epoch  train_loss  train_acc  val_loss   val_acc  acc_pred  \\\n",
       "0                 19    0.407172   0.807441  0.421311  0.805792  0.785917   \n",
       "75               300    0.423586   0.796365  0.422230  0.809767  0.782510   \n",
       "96               300    0.427701   0.797217  0.423438  0.813742  0.797842   \n",
       "12                20    0.414693   0.802613  0.424286  0.808064  0.790460   \n",
       "99               300    0.424164   0.794093  0.425792  0.805224  0.785349   \n",
       "24                16    0.408177   0.806873  0.426708  0.802953  0.786485   \n",
       "102              300    0.431711   0.802329  0.428115  0.810903  0.796139   \n",
       "105              300    0.430745   0.795229  0.429373  0.804656  0.797274   \n",
       "72               300    0.428388   0.797785  0.430013  0.797842  0.787621   \n",
       "42               300    0.439105   0.785004  0.431162  0.805792  0.789324   \n",
       "\n",
       "      time                                            history  \\\n",
       "0     1.28  <keras.callbacks.callbacks.History object at 0...   \n",
       "75   13.29  <keras.callbacks.callbacks.History object at 0...   \n",
       "96    9.64  <keras.callbacks.callbacks.History object at 0...   \n",
       "12    1.09  <keras.callbacks.callbacks.History object at 0...   \n",
       "99   21.34  <keras.callbacks.callbacks.History object at 0...   \n",
       "24    1.04  <keras.callbacks.callbacks.History object at 0...   \n",
       "102  15.97  <keras.callbacks.callbacks.History object at 0...   \n",
       "105  14.30  <keras.callbacks.callbacks.History object at 0...   \n",
       "72   10.23  <keras.callbacks.callbacks.History object at 0...   \n",
       "42    9.87  <keras.callbacks.callbacks.History object at 0...   \n",
       "\n",
       "                                               predict  \n",
       "0    [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "75   [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "96   [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "12   [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "99   [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "24   [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "102  [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "105  [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "72   [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  \n",
       "42   [[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stoped_at_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>acc_pred</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">128,2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>0.800548</td>\n",
       "      <td>0.432275</td>\n",
       "      <td>0.795152</td>\n",
       "      <td>0.788378</td>\n",
       "      <td>16.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.423394</td>\n",
       "      <td>0.803578</td>\n",
       "      <td>0.433037</td>\n",
       "      <td>0.796665</td>\n",
       "      <td>0.796706</td>\n",
       "      <td>11.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.427634</td>\n",
       "      <td>0.804525</td>\n",
       "      <td>0.436576</td>\n",
       "      <td>0.797235</td>\n",
       "      <td>0.794056</td>\n",
       "      <td>14.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.427465</td>\n",
       "      <td>0.797993</td>\n",
       "      <td>0.436603</td>\n",
       "      <td>0.791555</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>13.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.427319</td>\n",
       "      <td>0.798845</td>\n",
       "      <td>0.438193</td>\n",
       "      <td>0.790420</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>9.793333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32,32,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>206.666667</td>\n",
       "      <td>0.431724</td>\n",
       "      <td>0.799413</td>\n",
       "      <td>0.441133</td>\n",
       "      <td>0.790609</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>5.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">64,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.433156</td>\n",
       "      <td>0.794775</td>\n",
       "      <td>0.441762</td>\n",
       "      <td>0.790609</td>\n",
       "      <td>0.787431</td>\n",
       "      <td>9.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.436576</td>\n",
       "      <td>0.791177</td>\n",
       "      <td>0.444166</td>\n",
       "      <td>0.785685</td>\n",
       "      <td>0.784214</td>\n",
       "      <td>9.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32,32,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>206.333333</td>\n",
       "      <td>0.435378</td>\n",
       "      <td>0.792219</td>\n",
       "      <td>0.446660</td>\n",
       "      <td>0.775650</td>\n",
       "      <td>0.780996</td>\n",
       "      <td>5.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.439882</td>\n",
       "      <td>0.794396</td>\n",
       "      <td>0.446793</td>\n",
       "      <td>0.791366</td>\n",
       "      <td>0.781374</td>\n",
       "      <td>10.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">64,2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.442858</td>\n",
       "      <td>0.787485</td>\n",
       "      <td>0.448217</td>\n",
       "      <td>0.782846</td>\n",
       "      <td>0.772478</td>\n",
       "      <td>9.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.440265</td>\n",
       "      <td>0.788527</td>\n",
       "      <td>0.448374</td>\n",
       "      <td>0.786443</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>10.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.442151</td>\n",
       "      <td>0.789758</td>\n",
       "      <td>0.449082</td>\n",
       "      <td>0.787579</td>\n",
       "      <td>0.771531</td>\n",
       "      <td>7.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.442621</td>\n",
       "      <td>0.788054</td>\n",
       "      <td>0.449247</td>\n",
       "      <td>0.781520</td>\n",
       "      <td>0.775696</td>\n",
       "      <td>9.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32,32,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.448602</td>\n",
       "      <td>0.778398</td>\n",
       "      <td>0.452674</td>\n",
       "      <td>0.770731</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>10.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.445843</td>\n",
       "      <td>0.782468</td>\n",
       "      <td>0.454108</td>\n",
       "      <td>0.778869</td>\n",
       "      <td>0.772288</td>\n",
       "      <td>14.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">32,32,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>205.333333</td>\n",
       "      <td>0.448579</td>\n",
       "      <td>0.776223</td>\n",
       "      <td>0.454751</td>\n",
       "      <td>0.767889</td>\n",
       "      <td>0.768124</td>\n",
       "      <td>5.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.450436</td>\n",
       "      <td>0.781048</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.777357</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>10.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.453441</td>\n",
       "      <td>0.797236</td>\n",
       "      <td>0.459124</td>\n",
       "      <td>0.791935</td>\n",
       "      <td>0.780617</td>\n",
       "      <td>11.373333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.457439</td>\n",
       "      <td>0.776599</td>\n",
       "      <td>0.461828</td>\n",
       "      <td>0.771677</td>\n",
       "      <td>0.766042</td>\n",
       "      <td>11.456667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.473963</td>\n",
       "      <td>0.762874</td>\n",
       "      <td>0.476225</td>\n",
       "      <td>0.762023</td>\n",
       "      <td>0.757335</td>\n",
       "      <td>12.923333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.477013</td>\n",
       "      <td>0.767796</td>\n",
       "      <td>0.481445</td>\n",
       "      <td>0.762968</td>\n",
       "      <td>0.759038</td>\n",
       "      <td>9.373333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32,32,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.RMSprop'&gt;</th>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.484245</td>\n",
       "      <td>0.754165</td>\n",
       "      <td>0.487545</td>\n",
       "      <td>0.749718</td>\n",
       "      <td>0.749574</td>\n",
       "      <td>11.103333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.485648</td>\n",
       "      <td>0.746024</td>\n",
       "      <td>0.488511</td>\n",
       "      <td>0.744606</td>\n",
       "      <td>0.747871</td>\n",
       "      <td>11.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">128,2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.557677</td>\n",
       "      <td>0.710815</td>\n",
       "      <td>0.561189</td>\n",
       "      <td>0.709567</td>\n",
       "      <td>0.698088</td>\n",
       "      <td>12.823333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.583693</td>\n",
       "      <td>0.703239</td>\n",
       "      <td>0.584868</td>\n",
       "      <td>0.702572</td>\n",
       "      <td>0.700360</td>\n",
       "      <td>13.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32,32,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>103.000000</td>\n",
       "      <td>0.663117</td>\n",
       "      <td>0.740251</td>\n",
       "      <td>0.660280</td>\n",
       "      <td>0.738547</td>\n",
       "      <td>0.740867</td>\n",
       "      <td>3.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">128,2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.665659</td>\n",
       "      <td>0.598447</td>\n",
       "      <td>0.665660</td>\n",
       "      <td>0.598445</td>\n",
       "      <td>0.582624</td>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.703040</td>\n",
       "      <td>0.549413</td>\n",
       "      <td>0.703041</td>\n",
       "      <td>0.549413</td>\n",
       "      <td>0.535491</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">64,2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.714486</td>\n",
       "      <td>0.552064</td>\n",
       "      <td>0.714487</td>\n",
       "      <td>0.552064</td>\n",
       "      <td>0.545713</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.722375</td>\n",
       "      <td>0.521394</td>\n",
       "      <td>0.722374</td>\n",
       "      <td>0.521397</td>\n",
       "      <td>0.516752</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.837073</td>\n",
       "      <td>0.421999</td>\n",
       "      <td>0.837073</td>\n",
       "      <td>0.421998</td>\n",
       "      <td>0.433277</td>\n",
       "      <td>0.396667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.00</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.844097</td>\n",
       "      <td>0.433359</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.433359</td>\n",
       "      <td>0.448041</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">128,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.10</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.872816</td>\n",
       "      <td>0.436766</td>\n",
       "      <td>0.872819</td>\n",
       "      <td>0.436763</td>\n",
       "      <td>0.429869</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'keras.optimizers.Adam'&gt;</th>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.918819</td>\n",
       "      <td>0.434117</td>\n",
       "      <td>0.920541</td>\n",
       "      <td>0.432031</td>\n",
       "      <td>0.443498</td>\n",
       "      <td>13.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64,2</th>\n",
       "      <th>&lt;class 'keras.optimizers.SGD'&gt;</th>\n",
       "      <th>0.25</th>\n",
       "      <th>256</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.021160</td>\n",
       "      <td>0.376373</td>\n",
       "      <td>1.021159</td>\n",
       "      <td>0.376374</td>\n",
       "      <td>0.367973</td>\n",
       "      <td>0.306667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               stoped_at_epoch  \\\n",
       "layers  optimizer                          dropout batch_size                    \n",
       "128,2   <class 'keras.optimizers.RMSprop'> 0.10    256              300.000000   \n",
       "                                           0.00    256              300.000000   \n",
       "                                           0.25    256              300.000000   \n",
       "                                           0.50    256              300.000000   \n",
       "        <class 'keras.optimizers.Adam'>    0.00    256              300.000000   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.00    256              206.666667   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.10    256              300.000000   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256              300.000000   \n",
       "32,32,2 <class 'keras.optimizers.Adam'>    0.00    256              206.333333   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.10    256              300.000000   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.50    256              300.000000   \n",
       "                                           0.10    256              300.000000   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.00    256              300.000000   \n",
       "                                           0.25    256              300.000000   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.25    256              300.000000   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.00    256              300.000000   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.00    256              205.333333   \n",
       "        <class 'keras.optimizers.SGD'>     0.10    256              300.000000   \n",
       "        <class 'keras.optimizers.Adam'>    0.10    256              300.000000   \n",
       "                                           0.25    256              300.000000   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.50    256              300.000000   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.50    256              300.000000   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.25    256              300.000000   \n",
       "        <class 'keras.optimizers.Adam'>    0.50    256              300.000000   \n",
       "128,2   <class 'keras.optimizers.Adam'>    0.10    256              300.000000   \n",
       "                                           0.50    256              300.000000   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.50    256              103.000000   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.00    256                5.000000   \n",
       "                                           0.50    256                5.000000   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.10    256                5.000000   \n",
       "                                           0.50    256                5.000000   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.25    256                5.000000   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.00    256                5.000000   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.10    256                5.000000   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256              300.000000   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.25    256                5.000000   \n",
       "\n",
       "                                                               train_loss  \\\n",
       "layers  optimizer                          dropout batch_size               \n",
       "128,2   <class 'keras.optimizers.RMSprop'> 0.10    256           0.421605   \n",
       "                                           0.00    256           0.423394   \n",
       "                                           0.25    256           0.427634   \n",
       "                                           0.50    256           0.427465   \n",
       "        <class 'keras.optimizers.Adam'>    0.00    256           0.427319   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.00    256           0.431724   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.10    256           0.433156   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256           0.436576   \n",
       "32,32,2 <class 'keras.optimizers.Adam'>    0.00    256           0.435378   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.10    256           0.439882   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.50    256           0.442858   \n",
       "                                           0.10    256           0.440265   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.00    256           0.442151   \n",
       "                                           0.25    256           0.442621   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.25    256           0.448602   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.00    256           0.445843   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.00    256           0.448579   \n",
       "        <class 'keras.optimizers.SGD'>     0.10    256           0.450436   \n",
       "        <class 'keras.optimizers.Adam'>    0.10    256           0.453441   \n",
       "                                           0.25    256           0.457439   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.50    256           0.473963   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.50    256           0.477013   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.25    256           0.484245   \n",
       "        <class 'keras.optimizers.Adam'>    0.50    256           0.485648   \n",
       "128,2   <class 'keras.optimizers.Adam'>    0.10    256           0.557677   \n",
       "                                           0.50    256           0.583693   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.50    256           0.663117   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.00    256           0.665659   \n",
       "                                           0.50    256           0.703040   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.10    256           0.714486   \n",
       "                                           0.50    256           0.722375   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.25    256           0.837073   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.00    256           0.844097   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.10    256           0.872816   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256           0.918819   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.25    256           1.021160   \n",
       "\n",
       "                                                               train_acc  \\\n",
       "layers  optimizer                          dropout batch_size              \n",
       "128,2   <class 'keras.optimizers.RMSprop'> 0.10    256          0.800548   \n",
       "                                           0.00    256          0.803578   \n",
       "                                           0.25    256          0.804525   \n",
       "                                           0.50    256          0.797993   \n",
       "        <class 'keras.optimizers.Adam'>    0.00    256          0.798845   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.00    256          0.799413   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.10    256          0.794775   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256          0.791177   \n",
       "32,32,2 <class 'keras.optimizers.Adam'>    0.00    256          0.792219   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.10    256          0.794396   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.50    256          0.787485   \n",
       "                                           0.10    256          0.788527   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.00    256          0.789758   \n",
       "                                           0.25    256          0.788054   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.25    256          0.778398   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.00    256          0.782468   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.00    256          0.776223   \n",
       "        <class 'keras.optimizers.SGD'>     0.10    256          0.781048   \n",
       "        <class 'keras.optimizers.Adam'>    0.10    256          0.797236   \n",
       "                                           0.25    256          0.776599   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.50    256          0.762874   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.50    256          0.767796   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.25    256          0.754165   \n",
       "        <class 'keras.optimizers.Adam'>    0.50    256          0.746024   \n",
       "128,2   <class 'keras.optimizers.Adam'>    0.10    256          0.710815   \n",
       "                                           0.50    256          0.703239   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.50    256          0.740251   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.00    256          0.598447   \n",
       "                                           0.50    256          0.549413   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.10    256          0.552064   \n",
       "                                           0.50    256          0.521394   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.25    256          0.421999   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.00    256          0.433359   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.10    256          0.436766   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256          0.434117   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.25    256          0.376373   \n",
       "\n",
       "                                                               val_loss  \\\n",
       "layers  optimizer                          dropout batch_size             \n",
       "128,2   <class 'keras.optimizers.RMSprop'> 0.10    256         0.432275   \n",
       "                                           0.00    256         0.433037   \n",
       "                                           0.25    256         0.436576   \n",
       "                                           0.50    256         0.436603   \n",
       "        <class 'keras.optimizers.Adam'>    0.00    256         0.438193   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.00    256         0.441133   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.10    256         0.441762   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256         0.444166   \n",
       "32,32,2 <class 'keras.optimizers.Adam'>    0.00    256         0.446660   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.10    256         0.446793   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.50    256         0.448217   \n",
       "                                           0.10    256         0.448374   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.00    256         0.449082   \n",
       "                                           0.25    256         0.449247   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.25    256         0.452674   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.00    256         0.454108   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.00    256         0.454751   \n",
       "        <class 'keras.optimizers.SGD'>     0.10    256         0.455600   \n",
       "        <class 'keras.optimizers.Adam'>    0.10    256         0.459124   \n",
       "                                           0.25    256         0.461828   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.50    256         0.476225   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.50    256         0.481445   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.25    256         0.487545   \n",
       "        <class 'keras.optimizers.Adam'>    0.50    256         0.488511   \n",
       "128,2   <class 'keras.optimizers.Adam'>    0.10    256         0.561189   \n",
       "                                           0.50    256         0.584868   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.50    256         0.660280   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.00    256         0.665660   \n",
       "                                           0.50    256         0.703041   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.10    256         0.714487   \n",
       "                                           0.50    256         0.722374   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.25    256         0.837073   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.00    256         0.844098   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.10    256         0.872819   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256         0.920541   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.25    256         1.021159   \n",
       "\n",
       "                                                                val_acc  \\\n",
       "layers  optimizer                          dropout batch_size             \n",
       "128,2   <class 'keras.optimizers.RMSprop'> 0.10    256         0.795152   \n",
       "                                           0.00    256         0.796665   \n",
       "                                           0.25    256         0.797235   \n",
       "                                           0.50    256         0.791555   \n",
       "        <class 'keras.optimizers.Adam'>    0.00    256         0.790420   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.00    256         0.790609   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.10    256         0.790609   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256         0.785685   \n",
       "32,32,2 <class 'keras.optimizers.Adam'>    0.00    256         0.775650   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.10    256         0.791366   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.50    256         0.782846   \n",
       "                                           0.10    256         0.786443   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.00    256         0.787579   \n",
       "                                           0.25    256         0.781520   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.25    256         0.770731   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.00    256         0.778869   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.00    256         0.767889   \n",
       "        <class 'keras.optimizers.SGD'>     0.10    256         0.777357   \n",
       "        <class 'keras.optimizers.Adam'>    0.10    256         0.791935   \n",
       "                                           0.25    256         0.771677   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.50    256         0.762023   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.50    256         0.762968   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.25    256         0.749718   \n",
       "        <class 'keras.optimizers.Adam'>    0.50    256         0.744606   \n",
       "128,2   <class 'keras.optimizers.Adam'>    0.10    256         0.709567   \n",
       "                                           0.50    256         0.702572   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.50    256         0.738547   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.00    256         0.598445   \n",
       "                                           0.50    256         0.549413   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.10    256         0.552064   \n",
       "                                           0.50    256         0.521397   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.25    256         0.421998   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.00    256         0.433359   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.10    256         0.436763   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256         0.432031   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.25    256         0.376374   \n",
       "\n",
       "                                                               acc_pred  \\\n",
       "layers  optimizer                          dropout batch_size             \n",
       "128,2   <class 'keras.optimizers.RMSprop'> 0.10    256         0.788378   \n",
       "                                           0.00    256         0.796706   \n",
       "                                           0.25    256         0.794056   \n",
       "                                           0.50    256         0.796517   \n",
       "        <class 'keras.optimizers.Adam'>    0.00    256         0.784781   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.00    256         0.785728   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.10    256         0.787431   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256         0.784214   \n",
       "32,32,2 <class 'keras.optimizers.Adam'>    0.00    256         0.780996   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.10    256         0.781374   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.50    256         0.772478   \n",
       "                                           0.10    256         0.785728   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.00    256         0.771531   \n",
       "                                           0.25    256         0.775696   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.25    256         0.766610   \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.00    256         0.772288   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.00    256         0.768124   \n",
       "        <class 'keras.optimizers.SGD'>     0.10    256         0.776642   \n",
       "        <class 'keras.optimizers.Adam'>    0.10    256         0.780617   \n",
       "                                           0.25    256         0.766042   \n",
       "        <class 'keras.optimizers.RMSprop'> 0.50    256         0.757335   \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.50    256         0.759038   \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.25    256         0.749574   \n",
       "        <class 'keras.optimizers.Adam'>    0.50    256         0.747871   \n",
       "128,2   <class 'keras.optimizers.Adam'>    0.10    256         0.698088   \n",
       "                                           0.50    256         0.700360   \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.50    256         0.740867   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.00    256         0.582624   \n",
       "                                           0.50    256         0.535491   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.10    256         0.545713   \n",
       "                                           0.50    256         0.516752   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.25    256         0.433277   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.00    256         0.448041   \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.10    256         0.429869   \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256         0.443498   \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.25    256         0.367973   \n",
       "\n",
       "                                                                    time  \n",
       "layers  optimizer                          dropout batch_size             \n",
       "128,2   <class 'keras.optimizers.RMSprop'> 0.10    256         16.916667  \n",
       "                                           0.00    256         11.270000  \n",
       "                                           0.25    256         14.900000  \n",
       "                                           0.50    256         13.716667  \n",
       "        <class 'keras.optimizers.Adam'>    0.00    256          9.793333  \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.00    256          5.190000  \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.10    256          9.840000  \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256          9.693333  \n",
       "32,32,2 <class 'keras.optimizers.Adam'>    0.00    256          5.613333  \n",
       "        <class 'keras.optimizers.RMSprop'> 0.10    256         10.950000  \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.50    256          9.713333  \n",
       "                                           0.10    256         10.866667  \n",
       "        <class 'keras.optimizers.RMSprop'> 0.00    256          7.186667  \n",
       "                                           0.25    256          9.383333  \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.25    256         10.943333  \n",
       "64,2    <class 'keras.optimizers.Adam'>    0.00    256         14.180000  \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.00    256          5.230000  \n",
       "        <class 'keras.optimizers.SGD'>     0.10    256         10.840000  \n",
       "        <class 'keras.optimizers.Adam'>    0.10    256         11.373333  \n",
       "                                           0.25    256         11.456667  \n",
       "        <class 'keras.optimizers.RMSprop'> 0.50    256         12.923333  \n",
       "64,2    <class 'keras.optimizers.RMSprop'> 0.50    256          9.373333  \n",
       "32,32,2 <class 'keras.optimizers.RMSprop'> 0.25    256         11.103333  \n",
       "        <class 'keras.optimizers.Adam'>    0.50    256         11.053333  \n",
       "128,2   <class 'keras.optimizers.Adam'>    0.10    256         12.823333  \n",
       "                                           0.50    256         13.650000  \n",
       "32,32,2 <class 'keras.optimizers.SGD'>     0.50    256          3.826667  \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.00    256          0.310000  \n",
       "                                           0.50    256          0.430000  \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.10    256          0.316667  \n",
       "                                           0.50    256          0.320000  \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.25    256          0.396667  \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.00    256          0.250000  \n",
       "128,2   <class 'keras.optimizers.SGD'>     0.10    256          0.483333  \n",
       "        <class 'keras.optimizers.Adam'>    0.25    256         13.073333  \n",
       "64,2    <class 'keras.optimizers.SGD'>     0.25    256          0.306667  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.groupby(['layers','optimizer', 'dropout', 'batch_size']).mean().sort_values(by='val_loss', ascending=True).drop(['fold'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(name, history, legend, plot_val=True):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(14,6))\n",
    "    fig.suptitle(name)\n",
    "    \n",
    "    if not isinstance(history, list):\n",
    "        history = [history]\n",
    "        \n",
    "    for h in history:\n",
    "        acc = h.history['accuracy']\n",
    "        loss = h.history['loss']\n",
    "        if plot_val:\n",
    "            val_loss = h.history['val_loss']\n",
    "            val_acc = h.history['val_accuracy']\n",
    "        epochs = range(1, len(acc) + 1)\n",
    "\n",
    "        ax[0].set_title('Loss')\n",
    "        ax[0].set_xticks(ticks=epochs)\n",
    "        ax[0].set_ylabel('Loss')\n",
    "        \n",
    "        ax[0].plot(epochs, loss)\n",
    "        if plot_val:\n",
    "            ax[0].plot(epochs, val_loss)\n",
    "            \n",
    "        ax[1].set_title('Accuracy')\n",
    "        ax[1].set_xticks(ticks=list(epochs))\n",
    "        ax[1].set_xlabel('Epochs')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        ax[1].plot(epochs, acc)\n",
    "        if plot_val:\n",
    "            ax[1].plot(epochs, val_acc)\n",
    "        \n",
    "    ax[0].legend([l+' loss' for l in legend])\n",
    "    ax[1].legend([l+' accuracy' for l in legend])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def make_prediction(X_test, y_test):\n",
    "\n",
    "    yprednn=model.predict(X_test)\n",
    "    yprednn=yprednn.round()\n",
    "    print('Neural Network:\\n {}\\n'.format(\n",
    "        metrics.classification_report(yprednn, y_test)))\n",
    "    print('Neural Network:\\n {}\\n'.format(\n",
    "        metrics.confusion_matrix(yprednn, y_test)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in global_history:\n",
    "    plot_history(history['layers'], history['history'], legend=['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nos quedamos con las redes [128, 2] con Adam y 0.5 de Drop Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3697 samples, validate on 1585 samples\n",
      "Epoch 1/300\n",
      "3697/3697 [==============================] - 0s 47us/step - loss: 0.6215 - accuracy: 0.6557 - val_loss: 0.4743 - val_accuracy: 0.7621\n",
      "Epoch 2/300\n",
      "3697/3697 [==============================] - 0s 14us/step - loss: 0.4975 - accuracy: 0.7598 - val_loss: 0.4490 - val_accuracy: 0.7817\n",
      "Epoch 3/300\n",
      "3697/3697 [==============================] - 0s 16us/step - loss: 0.4818 - accuracy: 0.7712 - val_loss: 0.4402 - val_accuracy: 0.7899\n",
      "Epoch 4/300\n",
      "3697/3697 [==============================] - 0s 16us/step - loss: 0.4659 - accuracy: 0.7806 - val_loss: 0.4316 - val_accuracy: 0.7937\n",
      "Epoch 5/300\n",
      "3697/3697 [==============================] - 0s 16us/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4300 - val_accuracy: 0.7899\n",
      "Epoch 6/300\n",
      "3697/3697 [==============================] - 0s 15us/step - loss: 0.4458 - accuracy: 0.7858 - val_loss: 0.4266 - val_accuracy: 0.7924\n",
      "Epoch 7/300\n",
      "3697/3697 [==============================] - 0s 15us/step - loss: 0.4507 - accuracy: 0.7909 - val_loss: 0.4249 - val_accuracy: 0.7924\n",
      "Epoch 8/300\n",
      "3697/3697 [==============================] - 0s 28us/step - loss: 0.4422 - accuracy: 0.7928 - val_loss: 0.4250 - val_accuracy: 0.7912\n",
      "Epoch 9/300\n",
      "3697/3697 [==============================] - 0s 29us/step - loss: 0.4339 - accuracy: 0.7952 - val_loss: 0.4235 - val_accuracy: 0.7931\n",
      "Epoch 10/300\n",
      "3697/3697 [==============================] - 0s 29us/step - loss: 0.4272 - accuracy: 0.7979 - val_loss: 0.4241 - val_accuracy: 0.7893\n",
      "Epoch 11/300\n",
      "3697/3697 [==============================] - 0s 23us/step - loss: 0.4306 - accuracy: 0.7958 - val_loss: 0.4245 - val_accuracy: 0.7931\n",
      "Epoch 12/300\n",
      "3697/3697 [==============================] - 0s 23us/step - loss: 0.4290 - accuracy: 0.7982 - val_loss: 0.4243 - val_accuracy: 0.7924\n",
      "Epoch 13/300\n",
      "3697/3697 [==============================] - 0s 23us/step - loss: 0.4283 - accuracy: 0.7958 - val_loss: 0.4240 - val_accuracy: 0.7924\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "# Instanciamos la clase del modelo secuencial\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Agregamos la última capa con activación softmax\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "# Compilamos el modelo con el optimizador seleccionado\n",
    "\n",
    "optimizer = optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.3,\n",
    "                    batch_size=256, epochs=300,\n",
    "             callbacks=callbacks_list_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAHiCAYAAAA083AXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABckElEQVR4nO3deXxU1f3/8dcnM1kISSZAWEIGZQeBhMWIC4q4VUHrbtX261Kt1n5rrdpFu8q3/frr4lLrVqutW2tL/Vq3Kq4o4q6ISFgVEGUJW4AkLNnP7487CUMIIUAmd2byfj4eecydc5f5XNDwzsk555pzDhERERERiZ0UvwsQEREREUl2Ct0iIiIiIjGm0C0iIiIiEmMK3SIiIiIiMabQLSIiIiISYwrdIiIiIiIxptAtIpJgzKy/mTkzC7bh2EvN7K12+tyHzex/9/NcZ2aD26MOEZFEpNAtIhJDZrbCzGrMLK9Z+9xIEO3vU2kiItKBFLpFRGLvc+DCxjdmVgh08a8cERHpaArdIiKx9zfg4qj3lwCPRh9gZiEze9TMNpjZF2b2czNLiewLmNmtZrbRzJYDp7Zw7l/NrNTMVpvZ/5pZoKVCzOwoM/vQzMojr0ftqWgzG2tmc8ys0sz+BWQ0239apMd+i5m9Y2ZFe/lzmGJmyyP3cUvU/Q0ys9fMrCyy7zEzy436nBsi91VpZkvM7IRIe4qZ3WhmyyLnPm5m3fdSg4iILxS6RURi7z0gx8wOiYTh84G/NzvmLiAEDASOxQvp34zsuwI4DRgLFAPnNjv3EaAOGBw55ivAt5oXEQmkzwN3Aj2A24HnzaxHC8emAU/j/cDQHfg/4Jyo/eOAB4FvR671Z+BZM0tv5c/hrEj944AzgMsaLwf8BugLHAL0A6ZGPmcYcDVwmHMuGzgZWBE57xrgTLw/r77AZuCeVj5fRMQ3Ct0iIh2jsbf7JGAxsLpxR1QQ/4lzrtI5twK4DbgocsjXgDuccyudc5vwAmrjub2BycC1zrltzrn1wB+AC1qo4VTgM+fc35xzdc65f0Zq+WoLxx4BpEY+t9Y59wTwYdT+K4A/O+fed87VO+ceAaoj5+3J75xzm5xzXwJ3EBly45xb6px7xTlX7ZzbgPfDwLGRc+qBdGCEmaU651Y455ZF9n0b+JlzbpVzrhovqJ/blgmmIiIdTd+YREQ6xt+AWcAAmg0tAfKANOCLqLYvgILIdl9gZbN9jQ7GC8elZtbYltLs+EZ9m53b/HOaH7vaOeda+dxLzOx7UW1pkfP2pPk99AUws154ve/HANmR+jeDF8jN7Fq8QD3SzF4CrnfOrYnU8JSZNURdtx7oTdQPNSIi8UA93SIiHcA59wXehMopwJPNdm8EavFCZKOD2BkcS/GGXETva7QSr4c5zzmXG/nKcc6NbKGMxqAaLfpzopUCBRaV5Fv43JujPjPXOZcZ6T3fk+b3sCay/RvAAUXOuRzgv/CGnADgnPuHc+7oSO0O+F1UDZOb1ZDhnFPgFpG4o9AtItJxLgeOd85ti250ztUDjwM3m1m2mR0MXM/Ocd+PA9eYWdjMugE3Rp1bCrwM3GZmOZHJhYPM7Fh2Nx0YamZfN7OgmZ0PjACea+HYd/HGiV8TOfZsYHzU/geAq8zscPN0NbNTzSy7lfv/kZl1M7N+wPeBf0Xas4GtwBYzKwB+1HiCmQ0zs+MjY8WrgB14vdkA90X+zA6OHNvTzM5o5fNFRHyj0C0i0kGcc8ucc7P3sPt7wDZgOfAW8A+8iYrgBdyXgE+AOezeU34x3tCOhXjDMp4A8lv4/DK8CZk/AMqAHwOnOec2tnBsDXA2cGnkmudHf27kPq4A7o7sXxo5tjXPAB8Bc/EmdP410v4/eJMryyPt0feXDvwW77cBa4FewE8j+/4IPAu8bGaVeBNWD99LDSIivrBdh+uJiIiIiEh7U0+3iIiIiEiMKXSLiIiIiMSYQreIiIiISIwpdIuIiIiIxJhCt4iIiIhIjHWKJ1Lm5eW5/v37+12GiIiIiCS5jz76aKNzrmfz9k4Ruvv378/s2XtaGldEREREpH2Y2RcttWt4iYiIiIhIjCl0i4iIiIjEmEK3iIiIiEiMdYox3SIiIiLxrra2llWrVlFVVeV3KdIGGRkZhMNhUlNT23S8QreIiIhIHFi1ahXZ2dn0798fM/O7HGmFc46ysjJWrVrFgAED2nSOhpeIiIiIxIGqqip69OihwJ0AzIwePXrs028lFLpFRERE4oQCd+LY17+rmIZuMzvFzJaY2VIzu3EPx0wys7lmtsDM3oi09TOz181sUaT9+1HHTzWz1ZFz5prZlFjeg4iIiEhnUFZWxpgxYxgzZgx9+vShoKCg6X1NTU2r586ePZtrrrlmr59x1FFHtUutM2fO5LTTTmuXa3WUmI3pNrMAcA9wErAK+NDMnnXOLYw6Jhe4FzjFOfelmfWK7KoDfuCcm2Nm2cBHZvZK1Ll/cM7dGqvaRURERDqbHj16MHfuXACmTp1KVlYWP/zhD5v219XVEQy2HB2Li4spLi7e62e888477VJrIoplT/d4YKlzbrlzrgaYBpzR7JivA086574EcM6tj7yWOufmRLYrgUVAQQxrFREREZFmLr30Uq6//nqOO+44brjhBj744AOOOuooxo4dy1FHHcWSJUuAXXuep06dymWXXcakSZMYOHAgd955Z9P1srKymo6fNGkS5557LsOHD+cb3/gGzjkApk+fzvDhwzn66KO55ppr9tqjvWnTJs4880yKioo44ogjmDdvHgBvvPFGU0/92LFjqayspLS0lIkTJzJmzBhGjRrFm2++2e5/ZnsSy9VLCoCVUe9XAYc3O2YokGpmM4Fs4I/OuUejDzCz/sBY4P2o5qvN7GJgNl6P+Ob2LV1ERETEP//znwUsXFPRrtcc0TeHm746cp/P+/TTT3n11VcJBAJUVFQwa9YsgsEgr776Kj/96U/597//vds5ixcv5vXXX6eyspJhw4bxne98Z7el9T7++GMWLFhA3759mTBhAm+//TbFxcV8+9vfZtasWQwYMIALL7xwr/XddNNNjB07lqeffprXXnuNiy++mLlz53Lrrbdyzz33MGHCBLZu3UpGRgb3338/J598Mj/72c+or69n+/bt+/znsb9i2dPd0uhy1+x9EDgUOBU4GfiFmQ1tuoBZFvBv4FrnXON/eX8CBgFjgFLgthY/3OxKM5ttZrM3bNhwIPchIiIi0mmdd955BAIBAMrLyznvvPMYNWoU1113HQsWLGjxnFNPPZX09HTy8vLo1asX69at2+2Y8ePHEw6HSUlJYcyYMaxYsYLFixczcODApmX42hK633rrLS666CIAjj/+eMrKyigvL2fChAlcf/313HnnnWzZsoVgMMhhhx3GQw89xNSpUykpKSE7O3t//1j2WSx7ulcB/aLeh4E1LRyz0Tm3DdhmZrOA0cCnZpaKF7gfc8492XiCc67pb83MHgCea+nDnXP3A/cDFBcXNw/7IiIiInFrf3qkY6Vr165N27/4xS847rjjeOqpp1ixYgWTJk1q8Zz09PSm7UAgQF1dXZuOaRxisi9aOsfMuPHGGzn11FOZPn06RxxxBK+++ioTJ05k1qxZPP/881x00UX86Ec/4uKLL97nz9wfsezp/hAYYmYDzCwNuAB4ttkxzwDHmFnQzDLxhp8sMm8Nlr8Ci5xzt0efYGb5UW/PAubH7A5EREREpEl5eTkFBd40u4cffrjdrz98+HCWL1/OihUrAPjXv/6113MmTpzIY489BnhjxfPy8sjJyWHZsmUUFhZyww03UFxczOLFi/niiy/o1asXV1xxBZdffjlz5sxp93vYk5j1dDvn6szsauAlIAA86JxbYGZXRfbf55xbZGYvAvOABuAvzrn5ZnY0cBFQYmZzI5f8qXNuOvB7MxuDN1RlBfDtWN2DiIiIiOz04x//mEsuuYTbb7+d448/vt2v36VLF+69915OOeUU8vLyGD9+/F7PmTp1Kt/85jcpKioiMzOTRx55BIA77riD119/nUAgwIgRI5g8eTLTpk3jlltuITU1laysLB599NG9XL392P504yea4uJiN3v2bL/LEBEREdmjRYsWccghh/hdhu+2bt1KVlYWzjm++93vMmTIEK677jq/y2pRS39nZvaRc2639RP1RMoYcc6xtrxqv8YmiYiIiHRWDzzwAGPGjGHkyJGUl5fz7W8nx6AGhe4YmfbhSo74zQzWVlT5XYqIiIhIwrjuuuuYO3cuCxcu5LHHHiMzM9PvktqFQneMDO/jLUHzycpynysREREREb8pdMfIIfk5BFOMktVb/C5FRERERHym0B0jGakBhvXJZt4q9XSLiIiIdHYK3TFUFA4xb1W5JlOKiIiIdHIK3TFUWJBL+Y5avty03e9SRERERFo1adIkXnrppV3a7rjjDv77v/+71XMal2WeMmUKW7Zs2e2YqVOncuutt7b62U8//TQLFy5sev/LX/6SV199dR+qb9nMmTM57bTTDvg67UGhO4aKwiEADTERERGRuHfhhRcybdq0XdqmTZvGhRde2Kbzp0+fTm5u7n59dvPQ/atf/YoTTzxxv64VrxS6Y2hYn2zSginMW7XF71JEREREWnXuuefy3HPPUV1dDcCKFStYs2YNRx99NN/5zncoLi5m5MiR3HTTTS2e379/fzZu3AjAzTffzLBhwzjxxBNZsmRJ0zEPPPAAhx12GKNHj+acc85h+/btvPPOOzz77LP86Ec/YsyYMSxbtoxLL72UJ554AoAZM2YwduxYCgsLueyyy5rq69+/PzfddBPjxo2jsLCQxYsXt3p/mzZt4swzz6SoqIgjjjiCefPmAfDGG28wZswYxowZw9ixY6msrKS0tJSJEycyZswYRo0axZtvvnlgf7jE8DHwAqmBFEbk56inW0RERPbNCzfC2pL2vWafQpj82z3u7tGjB+PHj+fFF1/kjDPOYNq0aZx//vmYGTfffDPdu3envr6eE044gXnz5lFUVNTidT766COmTZvGxx9/TF1dHePGjePQQw8F4Oyzz+aKK64A4Oc//zl//etf+d73vsfpp5/OaaedxrnnnrvLtaqqqrj00kuZMWMGQ4cO5eKLL+ZPf/oT1157LQB5eXnMmTOHe++9l1tvvZW//OUve7y/m266ibFjx/L000/z2muvcfHFFzN37lxuvfVW7rnnHiZMmMDWrVvJyMjg/vvv5+STT+ZnP/sZ9fX1bN9+4EOF1dMdY0XhEPNXl1PfoMmUIiIiEt+ih5hEDy15/PHHGTduHGPHjmXBggW7DAVp7s033+Sss84iMzOTnJwcTj/99KZ98+fP55hjjqGwsJDHHnuMBQsWtFrPkiVLGDBgAEOHDgXgkksuYdasWU37zz77bAAOPfRQVqxY0eq13nrrLS666CIAjj/+eMrKyigvL2fChAlcf/313HnnnWzZsoVgMMhhhx3GQw89xNSpUykpKSE7O7vVa7eFerpjrCicy6PvfsHnG7cyuNeB/4WJiIhIJ9BKj3QsnXnmmVx//fXMmTOHHTt2MG7cOD7//HNuvfVWPvzwQ7p168all15KVVXrT9w2sxbbL730Up5++mlGjx7Nww8/zMyZM1u9zt5WgEtPTwcgEAhQV1e3z9cyM2688UZOPfVUpk+fzhFHHMGrr77KxIkTmTVrFs8//zwXXXQRP/rRj7j44otbvf7eqKc7xhonU+rJlCIiIhLvsrKymDRpEpdddllTL3dFRQVdu3YlFAqxbt06XnjhhVavMXHiRJ566il27NhBZWUl//nPf5r2VVZWkp+fT21tLY899lhTe3Z2NpWVlbtda/jw4axYsYKlS5cC8Le//Y1jjz12v+5t4sSJTZ85c+ZM8vLyyMnJYdmyZRQWFnLDDTdQXFzM4sWL+eKLL+jVqxdXXHEFl19+OXPmzNmvz4ymnu4YG9Qzi8y0ACWryznn0LDf5YiIiIi06sILL+Tss89uGmYyevRoxo4dy8iRIxk4cCATJkxo9fxx48Zx/vnnM2bMGA4++GCOOeaYpn2//vWvOfzwwzn44IMpLCxsCtoXXHABV1xxBXfeeWfTBEqAjIwMHnroIc477zzq6uo47LDDuOqqq/brvqZOnco3v/lNioqKyMzM5JFHHgG8ZRFff/11AoEAI0aMYPLkyUybNo1bbrmF1NRUsrKyePTRR/frM6NZZ3hwS3FxsWtcQ9IPX7vvXeoaGnjyv1v/j1REREQ6r0WLFnHIIYf4XYbsg5b+zszsI+dccfNjNbykAxSFQyxYU0FtfYPfpYiIiIiIDxS6O0BhOER1XQOfrdvqdykiIiIi4gOF7g4wOpwLoIfkiIiIiHRSCt0d4OAemeRkBJm3WiuYiIiIyJ51hrl2yWJf/64UujuAmVEUzlVPt4iIiOxRRkYGZWVlCt4JwDlHWVkZGRkZbT5HSwZ2kMJwiL+8uZyq2noyUgN+lyMiIiJxJhwOs2rVKjZs2OB3KdIGGRkZhMNtXw5aobuDFBWEqK13LF5byZh+uX6XIyIiInEmNTWVAQMG+F2GxIiGl3SQokjQLtEQExEREZFOR6G7g/QNZdCjaxqfrNJkShEREZHORqG7g3iTKUOUKHSLiIiIdDoK3R2oMJzLZ+sr2V5T53cpIiIiItKBFLo70OhwiAYHC9ZU+F2KiIiIiHQghe4OVBgOAfDJyi3+FiIiIiIiHUqhuwP1ys4gP5RBiZ5MKSIiItKpKHR3sMKCEPM0mVJERESkU1Ho7mCj++Xy+cZtlO+o9bsUEREREekgCt0drLDAG9e9QENMRERERDoNhe4OVtQ4mVJDTEREREQ6DYXuDpabmcZB3TMpWb3F71JEREREpIModPugMBzik5Xq6RYRERHpLBS6fTA6HGL1lh2Uba32uxQRERER6QAK3T4oLMgFYJ4mU4qIiIh0CgrdPhhVkIMZlGgypYiIiEinoNDtg+yMVAbmdWXeqi1+lyIiIiIiHUCh2yejw7l6MqWIiIhIJ6HQ7ZPCcIj1ldWsLa/yuxQRERERibGYhm4zO8XMlpjZUjO7cQ/HTDKzuWa2wMze2Nu5ZtbdzF4xs88ir91ieQ+xUhTOBdAQExEREZFOIGah28wCwD3AZGAEcKGZjWh2TC5wL3C6c24kcF4bzr0RmOGcGwLMiLxPOCPycwikmIaYiIiIiHQCsezpHg8sdc4td87VANOAM5od83XgSefclwDOufVtOPcM4JHI9iPAmbG7hdjpkhZgaO9sLRsoIiIi0gnEMnQXACuj3q+KtEUbCnQzs5lm9pGZXdyGc3s750oBIq+92r3yDlJUEGLeqi045/wuRURERERiKJah21poa54ug8ChwKnAycAvzGxoG89t/cPNrjSz2WY2e8OGDftyaocp6hdiy/ZaVm3e4XcpIiIiIhJDsQzdq4B+Ue/DwJoWjnnRObfNObcRmAWM3su568wsHyDyup4WOOfud84VO+eKe/bsecA3EwtFjU+m1LhuERERkaQWy9D9ITDEzAaYWRpwAfBss2OeAY4xs6CZZQKHA4v2cu6zwCWR7Usi10hIw/pkkxZI0QomIiIiIkkuGKsLO+fqzOxq4CUgADzonFtgZldF9t/nnFtkZi8C84AG4C/OufkALZ0bufRvgcfN7HLgSyIrniSitGAKh+Rnq6dbREREJMnFLHQDOOemA9Obtd3X7P0twC1tOTfSXgac0L6V+qcwHOKZj9fQ0OBISWlpKLuIiIiIJDo9kdJnReFcKqvr+Lxsm9+liIiIiEiMKHT7rCgcAvRkShEREZFkptDts8E9s+iSGtC4bhEREZEkptDts2AghZF9cxS6RURERJKYQnccKArnsmBNOXX1DX6XIiIiIiIxoNAdB4rCIapqG/hs/Va/SxERERGRGFDojgONkylLNMREREREJCkpdMeB/j26kp0e5BOtYCIiIiKSlBS640BKilEYDlGyWj3dIiIiIslIoTtOFIZDLCqtoLqu3u9SRERERKSdKXTHidHhXGrrHUvWVvpdioiIiIi0M4XuOFFY0PhkSg0xEREREUk2Ct1xItytC90yU/U4eBEREZEkpNAdJ8yMonCuerpFREREkpBCdxwpCof4bP1WdtRoMqWIiIhIMlHojiNF4VzqGxwLS9XbLSIiIpJMFLrjSOOTKT9ZqdAtIiIikkwUuuNI75wMeuek6yE5IiIiIklGoTvOFBbk6nHwIiIiIklGoTvOjA6HWL5hG5VVtX6XIiIiIiLtRKE7zhRGxnVriImIiIhI8lDojjNF4VwASrRet4iIiEjSUOiOM927phHu1kUPyRERERFJIgrdcWh0OJd5q7f4XYaIiIiItBOF7jhUGA6xctMONm2r8bsUEREREWkHCt1xqEiTKUVERESSikJ3HBpVEAndWq9bREREJCkodMehnIxUBuZ15RNNphQRERFJCgrdcaooHNKygSIiIiJJQqE7ThWGc1lbUcX6iiq/SxERERGRA6TQHadGRyZTar1uERERkcSn0B2nRvTNIcVgniZTioiIiCQ8he44lZkWZGjvbOZp2UARERGRhKfQHccKC0LMW1WOc87vUkRERETkACh0x7Gifrls2lbD6i07/C5FRERERA6AQnccKyrQZEoRERGRZKDQHceG52eTGjCFbhEREZEEp9Adx9KDAYb3ydEKJiIiIiIJTqE7zhWFQ5SsLqehQZMpRURERBKVQnecKwqHqKyqY0XZNr9LEREREZH9pNAd5woLcgEo0XrdIiIiIgkrpqHbzE4xsyVmttTMbmxh/yQzKzezuZGvX0bah0W1zTWzCjO7NrJvqpmtjto3JZb34LehvbNID6ZoMqWIiIhIAgvG6sJmFgDuAU4CVgEfmtmzzrmFzQ590zl3WnSDc24JMCbqOquBp6IO+YNz7tZY1R5PgoEURvbVZEoRERGRRBbLnu7xwFLn3HLnXA0wDThjP65zArDMOfdFu1aXQIrCucxfXUG9JlOKiIiIJKRYhu4CYGXU+1WRtuaONLNPzOwFMxvZwv4LgH82a7vazOaZ2YNm1q2lDzezK81stpnN3rBhw37dQLwoCofYUVvP0vVb/S5FRERERPZDLEO3tdDWvKt2DnCwc240cBfw9C4XMEsDTgf+L6r5T8AgvOEnpcBtLX24c+5+51yxc664Z8+e+1N/3CgK5wJoiImIiIhIgopl6F4F9It6HwbWRB/gnKtwzm2NbE8HUs0sL+qQycAc59y6qHPWOefqnXMNwAN4w1iS2sC8rmSlBzWZUkRERCRBxTJ0fwgMMbMBkR7rC4Bnow8wsz5mZpHt8ZF6yqIOuZBmQ0vMLD/q7VnA/BjUHldSUoxRBTnM07KBIiIiIgkpZquXOOfqzOxq4CUgADzonFtgZldF9t8HnAt8x8zqgB3ABc45B2BmmXgrn3y72aV/b2Zj8IaqrGhhf1IqCufy8NsrqKlrIC2o5dVFREREEknMQjc0DRmZ3qztvqjtu4G793DudqBHC+0XtXOZCaEoHKKmvoFP11UyqiDkdzkiIiIisg/UZZogiiJPpvxEkylFREREEo5Cd4Lo170LuZmplGgypYiIiEjCUehOEGZGYUGITxS6RURERBKOQncCKQqH+HRdJVW19X6XIiIiIiL7QKE7gRSFc6lvcCxYU+F3KSIiIiKyDxS6E0hR2Fu1pESTKUVEREQSikJ3AumTk0HP7HQ9JEdEREQkwSh0JxAzo6ggpMfBi4iIiCQYhe4EUxTOZdmGrWytrvO7FBERERFpI4XuBFMUDuEczNcQExEREZGEodCdYAqbJlMqdIuIiIgkCoXuBJOXlU5Bbhc9Dl5EREQkgSh0J6CicIgSDS8RERERSRgK3QmoMBzii7LtbNle43cpIiIiItIGCt0JaHQ4F0C93SIiIiIJQqE7AY0q8CZTar1uERERkcSg0J2AQl1SGZDXlXmaTCkiIiKSEBS6E1ShnkwpIiIikjAUuhNUUThEaXkV6yur/C5FRERERPZCoTtBFTVOplRvt4iIiEjcU+hOUCP75pBimkwpIiIikggUuhNU1/Qgg3tladlAERERkQSg0J3ACgtymbdqC845v0sRERERkVYodCew0f1CbNxaQ2m5JlOKiIiIxDOF7gRW2PSQnC3+FiIiIiIirVLoTmCH5OcQTDFNphQRERGJcwrdCSwjNcCwPtkK3SIiIiJxTqE7wRWFNZlSREREJN4pdCe4onCIiqo6vijb7ncpIiIiIrIHCt0JrigcmUyp9bpFRERE4pZCd4Ib2jubtGAK81Zu8bsUEREREdkDhe4ElxpIYUR+jnq6RUREROKYQncSGB0OMX91OfUNmkwpIiIiEo8UupNAYTiX7TX1LN+w1e9SRERERKQFCt1JYHRkMuUnWq9bREREJC4pdCeBgT2zyEwLUKLHwYuIiIjEJYXuJBBIMUYVhDSZUkRERCROKXQniaKCEAvXVFBb3+B3KSIiIiLSjEJ3kijql0t1XQOfrqv0uxQRERERaUahO0kUFUSeTKnJlCIiIiJxR6E7SRzcI5OcjKBCt4iIiEgcimnoNrNTzGyJmS01sxtb2D/JzMrNbG7k65dR+1aYWUmkfXZUe3cze8XMPou8dovlPSQKM6MonMs8rWAiIiIiEndiFrrNLADcA0wGRgAXmtmIFg590zk3JvL1q2b7jou0F0e13QjMcM4NAWZE3gtQFA6xZG0lVbX1fpciIiIiIlFi2dM9HljqnFvunKsBpgFntMN1zwAeiWw/ApzZDtdMCkXhEHUNjkWlFX6XIiIiIiJRYhm6C4CVUe9XRdqaO9LMPjGzF8xsZFS7A142s4/M7Mqo9t7OuVKAyGuvlj7czK40s9lmNnvDhg0HdicJoiicC0CJ1usWERERiSuxDN3WQptr9n4OcLBzbjRwF/B01L4JzrlxeMNTvmtmE/flw51z9zvnip1zxT179tyXUxNWfiiDvKw0Plmp0C0iIiIST2IZulcB/aLeh4E10Qc45yqcc1sj29OBVDPLi7xfE3ldDzyFN1wFYJ2Z5QNEXtfH8B4SiplRWBCiZPUWv0sRERERkSixDN0fAkPMbICZpQEXAM9GH2BmfczMItvjI/WUmVlXM8uOtHcFvgLMj5z2LHBJZPsS4JkY3kPCKQrnsnT9VrZV1/ldioiIiIhEBGN1YedcnZldDbwEBIAHnXMLzOyqyP77gHOB75hZHbADuMA558ysN/BUJI8HgX84516MXPq3wONmdjnwJXBerO4hERWFQzQ4WLCmgvEDuvtdjoiIiIgQw9ANTUNGpjdruy9q+27g7hbOWw6M3sM1y4AT2rfS5FEYbnwy5RaFbhEREZE4oSdSJple2RnkhzL0ZEoRERGROKLQnYSKwiE9mVJEREQkjih0J6GicC4ryrZTvr3W71JEREREBIXupFQUGdc9f42GmIiIiIjEA4XuJFRY4IXuTzTERERERCQuKHQnodzMNA7ukUmJJlOKiIiIxAWF7iRVWBDSCiYiIiIicUKhO0mNDueyessONm6t9rsUERERkU5PoTtJNT4kR0NMRERERPyn0J2kRhWEMENDTERERETigEJ3kspKDzKoZ5YekiMiIiISBxS6k1hRQYh5q8txzvldioiIiEinptCdxIrCITZUVrO2osrvUkREREQ6NYXuJFYYzgU0rltERETEbwrdSWxk3xwCKaZx3SIiIiI+U+hOYhmpAYb2zlZPt4iIiIjPFLqT3OhwiBJNphQRERHxlUJ3kisMh9iyvZaVm3b4XYqIiIhIp6XQneRGN06mXL3F1zpEREREOjOF7iQ3tHc2aYEUjesWERER8ZFCd5JLC6ZwSN8crWAiIiIi4iOF7k6gqCDE/NUVNDRoMqWIiIiIHxS6O4GicIit1XUs37jN71JEREREOiWF7k6gqOnJlFt8rUNERESks1Lo7gQG9exKl9SAJlOKiIiI+EShuxMIBlIYVaDJlCIiIiJ+UejuJAoLclmwpoK6+ga/SxERERHpdBS6O4nR/UJU1zXw6bqtfpciIiIi0ukodHcShQUhAEr0ZEoRERGRDqfQ3Un079GV7Iwgn2gypYiIiEiHU+juJFJSjMKCECUK3SIiIiIdTqG7EykK57J4bQXVdfV+lyIiIiLSqSh0dyJF4RC19Y7FpZV+lyIiIiLSqSh0dyJFYW8y5bzVGmIiIiIi0pEUujuRgtwudO+axryVW/wuRURERKRTUejuRMyMonCIEvV0i4iIiHQohe5OpqggxKfrKtleU+d3KSIiIiKdhkJ3J1MYzqXBwcI1FX6XIiIiItJpKHR3Mo2TKfWQHBEREZGOo9DdyfTOyaB3Tjolq7b4XYqIiIhIp6HQ3QkVhXOZp55uERERkQ7TptBtZl3NLCWyPdTMTjez1Dacd4qZLTGzpWZ2Ywv7J5lZuZnNjXz9MtLez8xeN7NFZrbAzL4fdc5UM1sddc6Utt+ugDeZcvnGbVRU1fpdioiIiEinEGzjcbOAY8ysGzADmA2cD3xjTyeYWQC4BzgJWAV8aGbPOucWNjv0Tefcac3a6oAfOOfmmFk28JGZvRJ17h+cc7e2sXZppqhfLgDzV5Vz1OA8f4sRERER6QTaOrzEnHPbgbOBu5xzZwEj9nLOeGCpc265c64GmAac0ZYPc86VOufmRLYrgUVAQRtrlb0oLNCTKUVEREQ6UptDt5kdidez/XykbW+95AXAyqj3q2g5OB9pZp+Y2QtmNrKFD+4PjAXej2q+2szmmdmDkd73lgq+0sxmm9nsDRs27KXUzqV71zT6de/CPE2mFBEREekQbQ3d1wI/AZ5yzi0ws4HA63s5x1poc83ezwEOds6NBu4Cnt7lAmZZwL+Ba51zjQtL/wkYBIwBSoHbWvpw59z9zrli51xxz54991Jq51NUoMmUIiIiIh2lTaHbOfeGc+5059zvIhMqNzrnrtnLaauAflHvw8CaZtetcM5tjWxPB1LNLA8gMlHz38Bjzrkno85Z55yrd841AA/gDWORfVQUDrFq8w7Ktlb7XYqIiIhI0mvr6iX/MLMcM+sKLASWmNmP9nLah8AQMxtgZmnABcCzza7bx8wssj0+Uk9ZpO2vwCLn3O3NzsmPensWML8t9yC7Kow8JKdE47pFREREYq6tw0tGRIZ3nAlMBw4CLmrtBOdcHXA18BLeRMjHI0NTrjKzqyKHnQvMN7NPgDuBC5xzDpgQuf7xLSwN+HszKzGzecBxwHVtvVnZqXEyZYmGmIiIiIjEXFuXDEyNDPc4E7jbOVdrZs3HZ+8mMmRkerO2+6K27wbubuG8t2h5TDjOuVbDvrRNdkYqA3t21ePgRURERDpAW3u6/wysALoCs8zsYKCi1TMk7o0O51KyeovfZYiIiIgkvbZOpLzTOVfgnJviPF/gDe2QBFZYEGJdRTXrKqr8LkVEREQkqbV1ImXIzG5vXPfazG7D6/WWBFYUmUyppQNFREREYqutw0seBCqBr0W+KoCHYlWUdIyRfUOkGHpIjoiIiEiMtXUi5SDn3DlR7//HzObGoB7pQF3SAgztna2ebhEREZEYa2tP9w4zO7rxjZlNAHbEpiTpSEXhEPNWbcFbqVFEREREYqGtofsq4B4zW2FmK/CW+ft2zKqSDlMYzmXz9lpWbdbPUCIiIiKx0tbVSz5xzo0GioAi59xY4PiYViYdYrQmU4qIiIjEXFt7ugFwzlVEnkwJcH0M6pEONqxPNqkBY57W6xYRERGJmX0K3c20+MRISSzpwQCH5Ocwb6V6ukVERERi5UBCt2beJYnCghDzV5fT0KC/UhEREZFYaDV0m1mlmVW08FUJ9O2gGiXGRodzqayu4/OybX6XIiIiIpKUWl2n2zmX3VGFiH8KI5MpS1aVM6hnls/ViIiIiCSfAxleIkliSK8sMlJTtIKJiIiISIwodAvBQAoj+4b0OHgRERGRGFHoFsCbTLlgTQV19Q1+lyIiIiKSdBS6BYDR/ULsqK1n6YatfpciIiIiknQUugWAwoJcQE+mFBEREYkFhW4BYGBeV7LSgxrXLSIiIhIDCt0CQEqKMaoghxL1dIuIiIi0O4VuaTI6nMui0kpq6jSZUkRERKQ9KXRLk8JwiJr6BpasrfS7FBEREZGkotAtTUaHcwH4ROO6RURERNqVQrc0CXfrQrfMVI3rFhEREWlnCt3SxMwoDOeqp1tERESknSl0yy6KCkJ8tn4rO2rq/S5FREREJGkodMsuisIh6hscC0s1xERERESkvSh0yy6KIpMp9WRKERERkfaj0C276J2TTs/sdE2mFBEREWlHCt2yCzNjdDikyZQiIiIi7UihW3ZTWJDL8o3bqKyq9bsUERERkaSg0C27KeoXwjmYv7rC71JEREREkoJCt+ymqCAEQMnqLf4WIiIiIpIkFLplNz2y0inI7cInmkwpIiIi0i4UuqVFReGQVjARERERaScK3dKionAuX27azuZtNX6XIiIiIpLwFLqlRUXhxnHd6u0WEREROVAK3dKiUZHJlPO0XreIiIjIAVPolhaFuqQyIK+rHgcvIiIi0g4UumWPisIhhW4RERGRdqDQLXtUWBBibUUV6yuq/C5FREREJKHFNHSb2SlmtsTMlprZjS3sn2Rm5WY2N/L1y72da2bdzewVM/ss8totlvfQmY3ulwug3m4RERGRAxSz0G1mAeAeYDIwArjQzEa0cOibzrkxka9fteHcG4EZzrkhwIzIe4mBEfk5pBjM0womIiIiIgcklj3d44GlzrnlzrkaYBpwRjucewbwSGT7EeDM9itZonVNDzK4VxYlWsFERERE5IDEMnQXACuj3q+KtDV3pJl9YmYvmNnINpzb2zlXChB57dXSh5vZlWY228xmb9iw4UDuo1MrCucyb1U5zjm/SxERERFJWLEM3dZCW/PkNgc42Dk3GrgLeHofzm2Vc+5+51yxc664Z8+e+3KqRCkKhyjbVsOack2mFBEREdlfsQzdq4B+Ue/DwJroA5xzFc65rZHt6UCqmeXt5dx1ZpYPEHldH5vyBbyeboB5K7f4WoeIiIhIIotl6P4QGGJmA8wsDbgAeDb6ADPrY2YW2R4fqadsL+c+C1wS2b4EeCaG99DpDe+TTTDFNJlSRERE5AAEY3Vh51ydmV0NvAQEgAedcwvM7KrI/vuAc4HvmFkdsAO4wHmDh1s8N3Lp3wKPm9nlwJfAebG6B4GM1ADD87P54PNN1NU3EAxoaXcRERGRfWWdYYJccXGxmz17tt9lJKw7Z3zG7a98yqiCHG4+s7Bp/W4RERER2ZWZfeScK27erm5L2avvHT+Yu78+lvUV1Zx579v88pn5VFTV+l2WiIiISMJQ6Ja9MjNOK+rLqz84lkuO7M/f3vuCE257g/98skZLCYqIiIi0gUK3tFlORipTTx/JM9+dQO+cdL73z4+5+MEPWLFxm9+liYiIiMQ1hW7ZZ0XhXJ757tFM/eoIPv5yC1+5YxZ3zfiM6rp6v0sTERERiUsK3bJfAinGpRMGMOMHx3LSiN7c9sqnTP7jm7yzbKPfpYmIiIjEHYVuOSC9czK45+vjePibh1FX7/j6A+9z/b/msnFrtd+liYiIiMQNhW5pF5OG9eLl6yZy9XGD+c+8NZxw2xv884MvaWjQREsRERERhW5pNxmpAX548jBe+P4xDO+TzU+eLOHc+95hUWmF36WJiIiI+EqhW9rd4F7ZTLvyCG49bzQryrZz2l1v8f+mL2J7TZ3fpYmIiIj4QqFbYsLMOPfQMDOuP5bzDg1z/6zlnHT7LF5ZuM7v0kREREQ6nEK3xFS3rmn89pwinrjqSLLSg1zx6GyueHQ2q7fs8Ls0ERERkQ6j0C0dorh/d5675mhunDycNz/bwEm3v8EDs5ZTW9/gd2kiIiIiMafQLR0mNZDCVccO4pXrjuXIgT24efoivnrXW3z0xWa/SxMRERGJKYVu6XD9umfyl0uKue+/DqV8Ry3n/OkdfvJkCeXba/0uTURERCQmFLrFF2bGKaP68Mr1x/Ktowfw+OyVHH/bTJ76eBXOaW1vERERSS4K3eKrrPQgPz9tBM9ePYFw90yu+9cnfP2B91m2YavfpYmIiIi0G4VuiQsj+4Z48jtH8b9njmL+mnIm3/Emt7/yKVW19X6XJiIiInLAFLolbgRSjP864mBe+8EkphT24c4Zn3HKHbN487MNfpcmIiIickAUuiXu9MxO544LxvLYtw7HzLjorx9wzT8/Zn1lld+liYiIiOwXhW6JWxMG5/HC94/h2hOH8OL8tZxw2xv87d0V1DdooqWIiIgkFoVuiWsZqQGuPXEoL157DEXhEL94ZgFn3/s281eX+12aiIiISJspdEtCGNgzi79ffjh/vGAMq7fs4PS73+JX/1nI1uo6v0sTERER2SuFbkkYZsYZYwqYcf0kvn74QTz0zueceNsbvFBSqrW9RUREJK4pdEvCCWWm8r9nFvLkd46ie9c0vvPYHC57+ENWbtrud2kiIiIiLVLoloQ19qBuPHv1BH5+6iG8//kmTvrDG9w7cyk1dQ1+lyYiIiKyC4VuSWjBQArfOmYgr15/LJOG9uL3Ly7htLve5IPPN/ldmoiIiEgThW5JCn1zu3DfRYfy10uK2VZdz9f+/C4/fuITNm2r8bs0EREREYVuSS4nHNKbV66fyFXHDuLJOas54baZPD57pSZaioiIiK8UuiXpZKYFuXHycJ675mgG9czix0/M4/w/v8en6yr9Lk1EREQ6KYVuSVrD++Tw+LeP5HfnFPLp+kqm/PFNfv/iYnbU1PtdmoiIiHQyCt2S1FJSjPMPO4gZ1x/LmWMLuHfmMr5yxxvMXLLe79JERESkE1Holk6hR1Y6t543mmlXHkFqIIVLH/qQ7/3zY9ZXVvldmoiIiHQCCt3SqRwxsAcvfP8YrjtxKC/NX8sJt73B39/7goYGTbQUERGR2FHolk4nPRjg+ycO4cVrj6GwIMTPn57Pufe9w+K1FX6XJiIiIklKoVs6rYE9s3jsW4dz+9dGs6JsO6fd+Ra/fUETLUVERKT9KXRLp2ZmnD0uzIzrj+XscQXc98YyTvqDJlqKiIhI+1LoFgG6dU3j9+d6Ey3Tg95Ey6v/MYf1FZpoKSIiIgdOoVskyhEDezD9+8dw/UlDeXnhOk64XRMtRURE5MApdIs0kx4McM0JQ3jx+zsnWp6jiZYiIiJyABS6RfYgeqLlF5poKSIiIgcgpqHbzE4xsyVmttTMbmzluMPMrN7Mzo28H2Zmc6O+Kszs2si+qWa2OmrflFjeg3Rue5po+bomWoqIiMg+iFnoNrMAcA8wGRgBXGhmI/Zw3O+AlxrbnHNLnHNjnHNjgEOB7cBTUaf9oXG/c256rO5BpFHziZbffOhDvquJliIiItJGsezpHg8sdc4td87VANOAM1o47nvAv4E9dR2eACxzzn0RmzJF2q5xouUPThrKKwvXccJtb/A3TbQUERGRvYhl6C4AVka9XxVpa2JmBcBZwH2tXOcC4J/N2q42s3lm9qCZdWuPYkXaKj0Y4HsnDOGlaydS1C/ELyITLReVaqKliIiItCyWodtaaGveHXgHcINzrsWZaWaWBpwO/F9U85+AQcAYoBS4bQ/nXmlms81s9oYNG/at8vbQ0ABfvt/xnysdZkBeV/5++eH84fzIRMu73uI3Lyxie02d36WJiIhInIll6F4F9It6HwbWNDumGJhmZiuAc4F7zezMqP2TgTnOuXWNDc65dc65eudcA/AA3jCW3Tjn7nfOFTvninv27HnAN7PPPvwLPHgyfPxYx3+2dBgz46yx3kTLc8eF+fMby/nKH2ZpoqWIiIjsIpah+0NgiJkNiPRYXwA8G32Ac26Ac66/c64/8ATw3865p6MOuZBmQ0vMLD/q7VnA/BjUfuDGXQQDJ8Ez34WP/+53NRJj3bqm8btzi/iXJlqKiIhIC2IWup1zdcDVeKuSLAIed84tMLOrzOyqvZ1vZpnAScCTzXb93sxKzGwecBxwXTuX3j5Su8CF/4RBx8EzV8Ocv/ldkXSAwzXRUkRERFpgziV/GCguLnazZ8/258Nrd8C0b8Cy1+D0u7wecOkUPt+4jZ8/XcLbS8sY0y+X35xdyCH5OX6XJSIiIjFkZh8554qbt+uJlLGW2gUu+AcMOh6evRo+esTviqSDRE+0/HKTJlqKiIh0ZgrdHSE1wwveg0+E/1wDHz3sd0XSQfY40XKxJlqKiIh0JgrdHSU1A85/DAafBP/5Psx+yO+KpAM1TrR8/NtHkpEa4JsPf8h3H5vDOk20FBER6RQUujtSagZc8BgM+Qo8dy3MftDviqSDjR/QnenXRCZaLlrHibe9wd/eXUG9JlqKiIgkNYXujhZMh/P/DkNOhueugw//6ndF0sHSgim7PtHymQWc86d3WLhGT7QUERFJVgrdfgimw/l/g6GnwPPXew/SkU6ncaLlHeePYeWm7Xz17rf4zXRNtBQREUlGCt1+CabD1x6FoZPh+R/ABw/4XZH4wMw4c2wBM35wLOcdGubPs5Zz0u2aaCkiIpJsFLr9FEyHrz3iBe/pP1Tw7sRyM9P47TneRMsuaZpoKSIikmwUuv3W2OM9bIqCtzRNtPzhVzTRUkREJJkodMeDYBqc9wgMO9UL3u/f73dF4qO0YApXHz+El6+dyOh+uZpoKSIikgQUuuNFMA3OexiGnwYv/Ajeu8/visRn/fO68rfLx+8y0fL/aaKliIhIQlLojifBNDj3IS94v3gDvPcnvysSn0VPtPxacZj7IxMtX1u8zu/SREREZB8odMebxh7vQ74KL94I797rd0USB3Iz0/jN2UX831VHkpkW4LKHZ3PV3z5iekkpKzZuo0FjvkVEROKaOZf8/1gXFxe72bNn+13GvqmvhScug0XPwsn/D478rt8VSZyoqWvg/lnLuPv1pVTVNgCQlR7kkPxsRuTnMKJvDiPyQwzpnUVGasDnakVERDoXM/vIOVe8W7tCdxyrr4V/Xw4Ln4Gv3AxHXe13RRJHqmrr+WzdVhaWlrNgTQUL11SwqLSCbTX1AARTjMG9sqKCuPeam5nmc+UiIiLJa0+hO+hHMdJGgVQ456+Awcs/Axwc9T2/q5I4kZEaoDAcojAcampraHB8uWk7C0u9EL5gTTlvL9vIkx+vbjqmbyiDEX1DTUF8ZN8cwt26YGZ+3IaIiEinoNAd7wKpcE7kMfEv/xycgwnX+FuTxK2UFKN/Xlf653VlSmF+U/vGrdUsagriFSwsreC1xetoHAqenRHcrUd8SK9s0oKa9iEiItIeFLoTQWOPtxm88gvAwYTv+12VJJC8rHSOGdKTY4b0bGrbUVPPknWVTT3iC0srmPbBSnbUesNTUgPGkF7ZuwTxQ/JzCHVJ9es2REREEpZCd6IIBOHsvwAGr/zS6/E++lq/q5IE1iUtwJh+uYzpl9vUVt/gWFG2bZce8ZlL1vPER6uajunXvYsXwvMjQ1T65tA3lKHhKSIiIq1Q6E4kgSCc/YDX4/3qTYCDo6/zuypJIoEUY1DPLAb1zOKro/s2ta+vrGJhJIQvWFPBojUVvLxwHY3zsHMzUyNBPKcpiA/qmUVqQMNTREREQKE78QSCcNb9gMGrU70e72Ou97sqSXK9sjPoNSyDScN6NbVtq65j8drKyKTNchauqeBv731BdZ23jGFaMIVhvbN3CeLD+2STnaHhKSIi0vkodCeiQBDO+rPX4z3jf8A1wMQf+l2VdDJd04McenA3Dj24W1NbXX0Dn2/c1tQjvnBNBS8vXMu/Zq9sOqZ/j8xdxomPyA/ROyddw1NERCSpKXQnqkAQzrzP237t14CDiT/ytSSRYCCFIb2zGdI7mzPGFADgnGNdRTULS8ubxoovWFPB9JK1TecV5HbhhsnD+WpRvsK3iIgkJYXuRNbU450Cr/0vOOBYBW+JL2ZGn1AGfUIZHD+8d1N7ZVWtNzxlTQX/99FKrvnnx0z74Et+dcZIBvfK9rFiERGR9qcnUiaDhnp4+r9h3jQ47mdw7I/9rkhkn9Q3OP7x/hfc8tISttfUc/kxA7jm+CF0TVe/gIiIJBY9kTKZpQTgzHu9Md6v3+xNrpx0g99VibRZIMW46Mj+TC7M53cvLObPbyzn2blr+MVpI5g8qo+GnIiISMLTel7JIiUAZ9wDo78OM/8fzPyt3xWJ7LO8rHRuOW80T1x1JLmZafz3Y3O4+MEPWL5hq9+liYiIHBCF7mSSEoAz7oYx34CZv4HXf+N3RSL7pbh/d/5z9QSmfnUEc7/cwsl3zOKWlxazvabO79JERET2i4aXJJuUAJx+F2DwRqS3+7if+FqSyP4IBlK4dMIAphTl89vpi7nn9WU8/fEafvnVEXxlRG8NORERkYSinu5k1Bi8x/yXF7xf/3/QCSbMSnLqlZ3B7eeP4V9XHkFWepBv/+0jvvnwh6zYuM3v0kRERNpMoTtZpaR4wXvsf8Ebv1PwloR3+MAePHfN0fzitBHMXrGZr/xhFre/vISq2nq/SxMREdkrhe5klpICX70Lxl4Es34fWctbwVsSV2oghcuPHsBrPziWyYV9uPO1pZx4+xu8unCd36WJiIi0SqE72aWkwFfvhHEXw5u3ek+vVPCWBNcrJ4M/XjCWf15xBF1SA3zr0dlc/vCHrNy03e/SREREWqTQ3RmkpMBpf4Rxl8Cbt8GMXyl4S1I4clAPpn//GH46ZTjvLi/jxNvf4I+vfqYhJyIiEncUujuLlBQ47Q449Jvw1u0w438UvCUppAZSuHLiIGb84FhOGtGbP7z6KSffMYvXl6z3uzQREZEmCt2dSUoKnHo7FF8Gb/0BXp2q4C1JIz/Uhbu/Po7HvnU4wRTjmw99yJWPzmbVZg05ERER/yl0dzYpKTDlNii+HN6+A169ScFbksqEwXm88P2J3HDKcN78bCMn3v4G97y+lOo6DTkRERH/KHR3RikpcGpj8P4jvPJLBW9JKmnBFL4zyRtyctywXtzy0hJOueNNZn26we/SRESkk1Lo7qzMvOB92LfgnTvhlV8oeEvS6ZvbhT/916E8ctl4AC5+8AO+8/ePWLNlh8+ViYhIZ6PHwHdmZjDlVsDgnbu80P2V//XaRZLIsUN78uK1x/CXNz/nrtc+Y+aSDVxzwhAuP3oAaUH1PYiISOzpX5vOzgym3ALjr4R374aXf64eb0lK6cEA3z1uMK9cdyzHDMnjdy8uZvIfZ/H20o1+lyYiIp1ATEO3mZ1iZkvMbKmZ3djKcYeZWb2ZnRvVtsLMSsxsrpnNjmrvbmavmNlnkddusbyHTsEMJv8exn/bC94v/VTBW5JWv+6Z3H9xMQ9dehh1DY5v/OV9rv7HHNaWV/ldmoiIJLGYhW4zCwD3AJOBEcCFZjZiD8f9Dniphcsc55wb45wrjmq7EZjhnBsCzIi8lwNlBpN/B4dfBe/dCy/+RMFbktpxw3vx0rUTuf6kobyycB0n3DaT+2cto7a+we/S4oLT//8iIu0qlmO6xwNLnXPLAcxsGnAGsLDZcd8D/g0c1sbrngFMimw/AswEbjjAWgW84H3KbwGD9//ktZ3yG43xlqSVkRrgmhOGcOaYAv7nPwv4f9MX83+zV/GrM0Zx5KAefpfXYbZV17GotIKFpRUsWF3BgtJyPl23lUE9szi1sA9TCvMZ2DPL7zJFRBJaLEN3AbAy6v0q4PDoA8ysADgLOJ7dQ7cDXjYzB/zZOXd/pL23c64UwDlXama9YlF8p2UWCdop8N49gPOCuIK3JLGDemTy10sP49WF65j6nwVc+MB7nDmmLz+dcgi9cjL8Lq9dbdxazYI1FSxYU86CNRUsWlPB52Xbmn6x1S0zlZF9Q3x9/EGUrC7n1pc/5daXP2V4n2xOLcxnSlE+gxTARUT2WSxDd0sprfnvK+8AbnDO1dvuoW6Cc25NJFS/YmaLnXOz2vzhZlcCVwIcdNBBba9avIB98s3e67t3e8NMJv9OwVuS3okjenP0kDzunbmM+95YxquL1nPdSUO55MiDCQYSa965c44vN21n4ZqKXUL2+srqpmMKcrswsm8OZ4wpYGTfHEb0zSE/lEH09+PS8h28ULKW6SWl3PbKp9z2ihfApxTmM6Uwn8G9FMBFRNrCYjVuz8yOBKY6506OvP8JgHPuN1HHfM7OcJ4HbAeudM493exaU4GtzrlbzWwJMCnSy50PzHTODWutluLiYjd79uzWDpGWOOetZvLu3TDqHDj8OxAuVviWTmHFxm1M/c8CZi7ZwPA+2fzqjFGMH9Dd77JaVFvfwGfrtjYF64WlXg92ZXUdAIEUY3DPrKZgPaJvDiPzQ4QyU/fpc6ID+OwvNgMogIuINGNmHzWbj+i1xzB0B4FPgROA1cCHwNedcwv2cPzDwHPOuSfMrCuQ4pyrjGy/AvzKOfeimd0ClDnnfhtZEaW7c+7HrdWi0H0AnIPXb/aeXFlfA7kHewG88FzoPdLv6kRiyjnHywvX8av/LGT1lh2cPa6An0w+hJ7Z6b7VtLW6jsWlu/Zef7ZuKzWRCaBdUgMMz89mZN8cRvYNMSI/h2F9sslIDbRrHWvLq3hhfmlTAHcOhvX2AvipRX0Y3Cu7XT9PRCRRdHjojnzoFLwhJAHgQefczWZ2FYBz7r5mxz7MztA9EHgqsisI/MM5d3PkuB7A48BBwJfAec65Ta3VodDdDnZsgcXPwfx/w/KZ4Bqg5yFQeA6MOhe6D/C7QpGY2VFTz92vf8b9s5aTkRrgh18ZxjcOPyjmQ042VFbv0nu9cE0FK6LGX3fvmub1XudHeq/7hhiQ15VASsf+NmpdRRUvlJQyvWQtH36xCedgaO8sL4AX5jOktwK4iHQevoTueKHQ3c62boCFT0PJE7DyPa+t4FAvfI86G7L7+FqeSKws37CVm55dwJufbWREfg6/PnMkhx584ENOGhoi469Ld/ZeL2w2/jrcrUtT73XjMJE+ObuOv44HLQXwIb0iAbwon6EK4CKS5BS6FbpjY8uXMP9JmP8ErC0BDPof7Q0/OeR0yIzPMbAi+8s5x4vz1/Kr5xZSWl7FeYeGuWHycPKy2jbkpKaugc/WVzYF64WRXuytUeOvh/TK8sZe50eGiPTNIdRl38Zfx4N1FVW8OH8tz5eU8uEKBXAR6RwUuhW6Y2/DEm/4SckTsGkZpKTC4BO8HvBhkyFdk6wkeWyrruOu15bylzeXk5kW4EenDOfr4w/aZWjH1sj61wtW7xwi8um6Smrrve+7XVIDHJKfvUvv9dDe7T/+Oh6sr6jixQVreX5eKR9EAvjgXjuHoAztnRV3vfYiIvtDoVuhu+M4B6VzvfA9/0moXAOpmTD0FK8HfPCJEPRvIppIe1q6vpJfPrOAd5aVMaogh5NH9GHx2koWrClnRdn2puN6dE3buXJIJGT379Hx46/jwfrKKl6K9IC//7kXwAf17Nq0Dviw3tkK4CKSsBS6Fbr90dAAX77rDT9Z8DTs2AQZITjkq14P+ICJkJJ8vXrSuTjneL6klF8/t5B1FdX0696Fkfk7e69H9g3ROyddQbIF0QH8g8830eBgYCSAn6oALiIJSKFbodt/9bXeyiclT3grodRsha69YORZXg94+DCtAS4Jraaugaq6enIyEm/8dTzYUFnNiwvWMn1eKe9/XrZLAJ9SmM/wPgrgIhL/FLoVuuNL7Q749CWvB/zTl6G+GnIP8tYAHxVZA1z/uIp0Whsqq3lpgfcgnveWRwJ4XtemB/Eckq8ALiLxSaFboTt+VZXD4ue9HvDlM8HVQ8/hXvguPAe6D/S7QhHx0cat1bw4f9cAPiCvK1MK+zClMJ8R+TkK4CISNxS6FboTQ+Ma4PP/7Y0FB+g7zht+MvJsyMn3tTwR8dfGrTt7wN9d5gXw/j0ym5YhVAAXEb8pdCt0J54tK2HBk14P+Np5NK0BPuocGHGG1gAX6eTKtlbz0oJ1XgBfXkZ9g2sK4FMK8xnZVwFcRDqeQrdCd2Lb+FlkCcInoGwppARh0AleD/iwKVoDXKSTK9tazcsLvQD+zjIvgB/c2AOuAC4iHUihW6E7OTgHpZ944Xv+k1CxGoJdYNgp3hjwISdpDXCRTm7TtpqmISiNAfyg7plMLuzDqYX5FBaEFMBFJGYUuhW6k09DA6x8z+sBX/g0bC+D9Mga4IXnQP+JEAj6XaWI+GjTthpeXrCW6fPX8s7SjdQ1OMLdujQNQRkdVgAXkfal0K3Qndzqa2H5G14P+KLnoKYSuvb01gAfdS70G68lCEU6uS3ba5qGoLy9dCO19Y6C3C5MHtWHyYX5jO2XS0onfEKoiLQvhW6F7s6jdgd89rLXA/7pS94a4KGDYNTZ3hjw3qMUwEU6ufLttbyyaB0vlJTy5mcbqalvID+UwSmjvCEo4w7qpgAuIvtFoVuhu3OqqvDWAJ//BCx73VsDPG+ot/zgyLOg13C/KxQRn1VU1fLqwnVML1nLrE83UFPfQO+cdCaPymfyqD4U9+9OQAFcRNpIoVuhW7aVeWO/FzwFK94CHPQ8xAvfI8+CnkP9rlBEfFZZVctri9fz/LxSZn66gZq6Bnpmp3tDUEblM36AAriItE6hW6FbolWug0XPegH8i3cAB71G7gzgeYP9rlBEfLa1uo7XFq/nhZJSXl+ynqraBvKy0jh5pDcEZfyA7gQDKX6XKSJxRqFboVv2pKJ0ZwBvfApmn0IvfI84E3oM8rU8EfHftuo6Zi7ZwPSSUl5bvJ4dtfX06JrGVyIB/IiBCuAi4lHoVuiWtihf7QXw+U/Cqg+8tvzROwN49wG+lici/ttRU8/MJeuZPn8tMxatY3tNPd0yUzl5pLcKylGDepCqAC7SaSl0K3TLvtqyEhY+4/WAr47899N37M4hKLkH+VufiPiuqraeNz71esBnLFrP1uo6Ql1S+cqI3kwpymfCoDzSggrgIp2JQrdCtxyIzV/sDOBr5nhtBcWRHvAzILefv/WJiO+qaut587ONTC8p5dWF66isriMnI8hJI/owpbAPRw/JIz0Y8LtMEYkxhW6Fbmkvmz7fuQpK6SdeW3j8zgAeKvC1PBHxX3VdPW99tpHpJWt5eeFaKqvqyE4PcuKI3kwpzOeYIXlkpCqAiyQjhW6FbomFsmU7A/jaEq+t3xE7A3hOvq/liYj/auoaeHvZRqbPK+Xlheso31FLVnqQEw7pxZTCfI4d2lMBXCSJKHQrdEusbVwKC5+CBU/DuvmAwcFHeQH8kNMhu7ffFYqIz2rrG3hnWRkvlJTy0oK1bN5eS9e0AMcf0pspo/owaVgvuqQpgIskMoVuhW7pSBuWeOF7wVOwYRFg0P9oGHmmF8CzevlcoIj4rba+gfeXb+L5SADftK2GLqkBjh/u9YAfN7wnmWlBv8sUkX2k0K3QLX5ZvygSwJ+EjZ+CpUQCeKQHvGue3xWKiM/q6hv44POdAXzj1hoyUlM4bpgXwI8f3ouu6QrgIolAoVuhW/zmXCSAP+UF8LKlYAEYcAyMPBsO+Spkdve7ShHxWX2D44PPN/HC/FJemL+WDZXVpAdTmDSsJyeP7MPRg/PolZPhd5kisgcK3QrdEk+c88Z9L3jK+9q03AvgAyd5PeDDT1UAFxHqGxwffbGZ6SWlvDC/lHUV1QAM7pXFUYN6cNSgPI4c2INQZqrPlYpII4VuhW6JV87B2nk7A/jmFZAShIHHRQL4FOjSze8qRcRnDQ2OhaUVvLNsI28vLeODzzexo7YeMxjVN8RRg70Qflj/bhoLLuIjhW6FbkkEzkHp3J0BfMuXkJIKg46HUWfDsMmQEfK7ShGJAzV1DXyyagtvL93IO8vK+PjLzdTWO1IDxth+3ThqcA8mDM5jdDhXT8UU6UAK3Qrdkmicg9VzvPHfC56GilUQSIPBJ3o94ENPgYwcv6sUkTixvaaO2Ss28/ayjbyztIz5a8pxDjLTAhzWvztHDfJC+Ij8HFJSzO9yRZKWQrdCtySyhgZY/dHOHvDKNd4QlMw8r+c7IwRdcnduN3210NalG6TnQEC/fhZJZuXba3l3eRnvLtvI28vKWLp+KwC5makcMaAHEwb34MhBeQzq2RUzhXCR9qLQrdAtyaKhAVZ9CJ+9BNs2QtUWqCrf9WvHFnD1rV8nLav1cN5akE/PgRT9ulokkayrqOLdZWVNw1FWb9kBQO+cdI4alNfUE943t4vPlYokNoVuhW7pTJyDmm3NwviWlsP5bu1boKoCaO17g3nBu9Vwvqee9lwv8KtnTcQ3zjm+3LSddyIh/N1lZZRtqwGgf49MjhrshfAjB/agR1a6z9X6r6HBsbaiipWbtvPlpu1Nr19u2s6aLVWkBo2cjFTvq0sw8trS+6D3GtnumhbUUJ8kpNCt0C3Sdg0NUFPZQkAvb1uQr6ls/fqWsmsQz+wBuQdD9wHQrT90i7xqzLpIh3DOsWRdJW8v9YajvLd8E1ur6wAY3iebCYPzmDC4B4f17052RnIuT1hZVdsUqFdu2tEUqldu2s6qzTuoqW9oOjbFoG9uF/p1y6SgWxfqGxwVO2qprKqjoqqWih21VFTVNf0Z7kmKQXZ0MG8ltGc3BvbGti6pZCm0xyWFboVukY5TXwfVFW3oZY9sb9vgLZW4Y9Ou18nssTOANw/k2fka4iISI3X1DZSsLm/qCZ/9xWZq6hoIpBijwyFvOMrgHow7qBsZqQG/y22TuvoGSsurmsL0zoDtbW/eXrvL8aEuqRzUPZODumcS7t6lafug7pn0ze1CamDv33/q6hvYWl1HxY7oMF7b7H3dHtv3FtrNIDs9uIde9T30siu0x5xCt0K3SPyrKvfC96bPvdfNn+98X75q13HqwQyvd7ylQN7tYEjVuFSR9lJVW8+cLzZ7IXzZRuatKqe+wZEeTKG4f7emMeGFBSGCbQijseCcY8v2WlZu3jVURw8DqW/YmXmCKUa4Wxf6RYXpxu1+3TLj4oFD+xbad7ZVRtoq9zG0Z2UESQ+mkB4MkB5MIS2Y0sJrgLRgCmmBFNJTG18DTe/TA7se1/z8xnOTefKuQrdCt0hiq6+F8pUtBPLIds3WXY/PzvdCePNA3n2A14OexN/wRWKtsqqWDz7fxNtLy3hn2UYWr/WGlGWnBzl8YPemnvBhvbPbNVxV19WzerM39GPl5h1eqC7bGbCbh8weXdN2CdWNwbpf9y7kh7oQSPJe3voGx9ZIGC9vQy97ZVUtNfUNVNc2eK919dTUNVBd10BN5KuuoX1yY2MQTw/uHtyjX1sO8IFdz48O9QHvB4bsjCCHD+zRLrXuK4VuhW6R5OUcbC9ruYd88wpvicVoadk7e8S7D9g1kIf6QcD/Hi6RRLJxazXvLS9rCuFflG0HIC8rjSMGequiTBiUR7/uXVoN4c45Nm6t2a2XunEYSGlFFdGxJS2YQr9uXXbrqT6oh9db3TVdS6O2t/oGFwniOwN5YyhvHtKr6xqoqa9vCvHRx7cU6Fs8P6q98QeC6si1WnNwj0ze+NFxHfSnsiuFboVukc6rdof3dM9Nn+8eyDevgPrqncdaAELh3YetNG7riaAie7Vqs7cySuMShesrvf/HCnK7MCHyuPrsjOBuw0BWbtrBjtpdlzvtnZPeNOQjOlQf1D2TnlnpGpPcSTnnIr3xDS2G9xQzRhX48/1aoVuhW0Ra0tAAW9fu2ksevb29bNfju3TfcyDP7qvJnSLNOOdYtmEb7yzb2LQ8YUXVzmEgmWmBZuOpuzSF6nC3zISZqCnSyJfQbWanAH8EAsBfnHO/3cNxhwHvAec7554ws37Ao0AfoAG43zn3x8ixU4ErgA2R03/qnJveWh0K3SKy36oqdvaINw/kW1buOrkzkAbZfbynfmbkemuSt7jdLbK2eWQ7PVtjzKXTqG9wLCqtoKa+gYO6Z9Kja1pST6qTzmdPoTtmg53MLADcA5wErAI+NLNnnXMLWzjud8BLUc11wA+cc3PMLBv4yMxeiTr3D865W2NVu4hIk4wcyC/yvpqrr/Mmd0YH8q3rYcdmb5nE9Yt2PoCovmbPn2GByIODmoXxPYb2qO3ULgrsklACKf792l/ET7GcYTAeWOqcWw5gZtOAM4CFzY77HvBv4LDGBudcKVAa2a40s0VAQQvnioj4JxD0hpZ0HwC0MmHHOajdvjOA79jsbTeG85a2N3++83jXyoShQNqee9D3th1MO8A/ABERaatYhu4CYGXU+1XA4dEHmFkBcBZwPFGhu9kx/YGxwPtRzVeb2cXAbLwe8c3tV7aISDszg7Su3leoYN/ObXw6aGNQjw7tLQX4ijWwbqG3XV3R+rVTu7bQg567czsl6P3A4BoAB46o7QZvX/R20z638weFNh3XuI82Huei2ttwHEBalndfGTmQnhP1Gmq2HfK29QOJiLSzWIbuln7f2XwA+R3ADc65+pbGc5lZFl4v+LXOucZ/Pf4E/DpyrV8DtwGXtXDulcCVAAcddND+3YGIiN9SUnaGwW77eG593c4ngu4ttFdtgU3Ldwb4uh1t+wxLAcx7Ndt1u2mf7b5vj8e1ck6Lx6VE/rVp5TjXAJXrIk9JrfB+iNmbYMbOcN4YxFsK53sK7+k53m9CpG2cg4Z6aKiL+mr+vqW2ODnHzBsmZineV0og6r/Hltqbfe2pfbd9UddtsT3F+57RYvs+1NTUFoh6b83eR+9PaeH4yPvW9jX9f945xPI7wiqgX9T7MNBssVyKgWmRwJ0HTDGzOufc02aWihe4H3POPdl4gnNuXeO2mT0APNfShzvn7gfuB28i5YHfjohIggkEoWsP72tf1VV7wWJPITmR/6FsqN8ZwBtfq8qj2sojP6w021+xemdb7fa9f05q11171vc1vKfnHNhqOI1Btr7am1NQXxt5jWzXVe/e1uqxLbTXt3SNmmbXjt4f/RUVWl393u8n1izg/Xan6aut7wM7f8viGrx7afxNS0N9C+0N3m+wWmrf275k1PwHhOY/BOwS4Pch/IcK4GuP+n13u4hl6P4QGGJmA4DVwAXA16MPcM4NaNw2s4eB5yKB24C/Aoucc7dHn2Nm+ZEx3+ANTZkfu1sQEemkgul+VxA7KYHI2PZ9/dVBlPraqIDeGM5bCOrR+xsf4NR4bGuTaxul5+waylMzvLDaUjiuq9m9bbdfMLeDlFRvLkEwzXsNpHkPlAqk7foVTPdW5gmmR+1P3fWcVkNtC22Wsvdj9vp+D8fE+w+S0cOpdgnwzYJ5i+31O89t9QeBlq5b3+wHiPqWPzd6f2v7dvnBovm1Wvis/a0jtavff2O7iVnods7VmdnVeKuSBIAHnXMLzOyqyP77Wjl9AnARUGJmcyNtjUsD/t7MxuB9J1kBfDs2dyAiIrIHgdT9/y1Co9qqZr3rzXvcmwf5cqjZBoF0b4x6dIjdJdg2tqc3C7qpkeP2EJJbvV7U/ngPp8mqaShGCrHtM5VY0cNxRERERETayZ7W6daj00REREREYkyhW0REREQkxhS6RURERERiTKFbRERERCTGFLpFRERERGJMoVtEREREJMYUukVEREREYkyhW0REREQkxhS6RURERERiTKFbRERERCTGFLpFRERERGJMoVtEREREJMYUukVEREREYkyhW0REREQkxhS6RURERERiTKFbRERERCTGFLpFRERERGJMoVtEREREJMbMOed3DTFnZhuAL3z46Dxgow+fGwu6l/iULPeSLPcBupd4lCz3AbqXeJUs95Is9wH+3svBzrmezRs7Rej2i5nNds4V+11He9C9xKdkuZdkuQ/QvcSjZLkP0L3Eq2S5l2S5D4jPe9HwEhERERGRGFPoFhERERGJMYXu2Lrf7wLake4lPiXLvSTLfYDuJR4ly32A7iVeJcu9JMt9QBzei8Z0i4iIiIjEmHq6RURERERiTKE7BszsQTNbb2bz/a7lQJlZPzN73cwWmdkCM/u+3zXtDzPLMLMPzOyTyH38j981HSgzC5jZx2b2nN+1HAgzW2FmJWY218xm+13PgTCzXDN7wswWR/6fOdLvmvaVmQ2L/F00flWY2bV+17W/zOy6yP/z883sn2aW4XdN+8vMvh+5jwWJ9nfS0r+LZtbdzF4xs88ir938rLEt9nAf50X+ThrMLK5Wy2jNHu7llsj3r3lm9pSZ5fpYYpvt4V5+HbmPuWb2spn19bNGUOiOlYeBU/wuop3UAT9wzh0CHAF818xG+FzT/qgGjnfOjQbGAKeY2RH+lnTAvg8s8ruIdnKcc25MvC3vtB/+CLzonBsOjCYB/36cc0sifxdjgEOB7cBT/la1f8ysALgGKHbOjQICwAX+VrV/zGwUcAUwHu+/rdPMbIi/Ve2Th9n938UbgRnOuSHAjMj7ePcwu9/HfOBsYFaHV3NgHmb3e3kFGOWcKwI+BX7S0UXtp4fZ/V5ucc4VRb6XPQf8sqOLak6hOwacc7OATX7X0R6cc6XOuTmR7Uq8EFHgb1X7znm2Rt6mRr4SdkKDmYWBU4G/+F2LeMwsB5gI/BXAOVfjnNvia1EH7gRgmXPOj4eLtZcg0MXMgkAmsMbnevbXIcB7zrntzrk64A3gLJ9rarM9/Lt4BvBIZPsR4MyOrGl/tHQfzrlFzrklPpW03/ZwLy9H/vsCeA8Id3hh+2EP91IR9bYrcfBvvkK3tJmZ9QfGAu/7XMp+iQzHmAusB15xziXkfUTcAfwYaPC5jvbggJfN7CMzu9LvYg7AQGAD8FBk2M9fzKyr30UdoAuAf/pdxP5yzq0GbgW+BEqBcufcy/5Wtd/mAxPNrIeZZQJTgH4+13SgejvnSsHr4AF6+VyP7Ooy4AW/izgQZnazma0EvoF6uiVRmFkW8G/g2mY/PSYM51x95NdMYWB85Ne1CcfMTgPWO+c+8ruWdjLBOTcOmIw3fGmi3wXtpyAwDviTc24ssI3E+HV5i8wsDTgd+D+/a9lfkTHCZwADgL5AVzP7L3+r2j/OuUXA7/B+/f8i8Ane8D+RdmdmP8P77+sxv2s5EM65nznn+uHdx9V+16PQLXtlZql4gfsx59yTftdzoCK/8p9J4o67nwCcbmYrgGnA8Wb2d39L2n/OuTWR1/V4Y4fH+1vRflsFrIr6DcoTeCE8UU0G5jjn1vldyAE4EfjcObfBOVcLPAkc5XNN+80591fn3Djn3ES8X6V/5ndNB2idmeUDRF7X+1yPAGZ2CXAa8A2XPOtK/wM4x+8iFLqlVWZmeGNUFznnbve7nv1lZj0bZ2GbWRe8f4wX+1rUfnLO/cQ5F3bO9cf79f9rzrmE7L0zs65mlt24DXwF79foCcc5txZYaWbDIk0nAAt9LOlAXUgCDy2J+BI4wswyI9/LTiABJ7c2MrNekdeD8CbuJfrfz7PAJZHtS4BnfKxFADM7BbgBON05t93veg5Es4nGpxMH/+YH/S4gGZnZP4FJQJ6ZrQJucs791d+q9tsE4CKgJDIeGuCnzrnp/pW0X/KBR8wsgPfD5uPOuYReai9J9Aae8vIQQeAfzrkX/S3pgHwPeCwyNGM58E2f69kvkTHDJwHf9ruWA+Gce9/MngDm4P2q/GPi8Cl1++DfZtYDqAW+65zb7HdBbdXSv4vAb4HHzexyvB+QzvOvwrbZw31sAu4CegLPm9lc59zJ/lXZNnu4l58A6cArke/L7znnrvKtyDbaw71MiXSCNABfAL7fh55IKSIiIiISYxpeIiIiIiISYwrdIiIiIiIxptAtIiIiIhJjCt0iIiIiIjGm0C0iIiIiEmMK3SIiIiIiMabQLSIiIiISYwrdIiIiIiIx9v8BsPFYj+8PbpAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Modelo de base')\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.xticks(ticks=list(epochs))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training accuracy', 'Validation accuracy']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      1294\n",
      "           1       0.63      0.56      0.59       467\n",
      "\n",
      "    accuracy                           0.80      1761\n",
      "   macro avg       0.74      0.72      0.73      1761\n",
      "weighted avg       0.79      0.80      0.79      1761\n",
      "\n",
      "\n",
      "Neural Network:\n",
      " [[1143  151]\n",
      " [ 207  260]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yprednn=model.predict(X_test)\n",
    "yprednn=yprednn.round()\n",
    "print('Neural Network:\\n {}\\n'.format(\n",
    "    classification_report(np.argmax(y_test, axis=1), np.argmax(yprednn, axis=1))))\n",
    "print('Neural Network:\\n {}\\n'.format(\n",
    "    confusion_matrix(np.argmax(y_test, axis=1), np.argmax(yprednn, axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1143  151]\n",
      " [ 207  260]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(yprednn, axis=1))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "plot_confusion_matrix(cm=cm, classes=['No', 'Yes'], title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "e52cyVZ2ZllS"
   ],
   "name": "1.PRACTICA_GUIADA_Regularizacion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
